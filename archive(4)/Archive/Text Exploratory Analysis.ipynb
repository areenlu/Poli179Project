{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b53cc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#import text\n",
    "data = pd.read_csv('/home/jandolina/teams/jack_areen_rubin/Data/fbpac-ads-en-US.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0cb308",
   "metadata": {},
   "source": [
    "# Using presence of words to determine whether an ad is related to the 2nd amendment or gun policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58fa92c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_related_words = ['gun','2nd amendment', 'second amendment', 'ar-15', 'assault rifle', 'pistols', 'shooting', 'mass shooting', 'school shooting', 'march for our lives']\n",
    "\n",
    "# Function to check if any word from the list is present in the text\n",
    "def contains_word(text, word_list):\n",
    "    for word in word_list:\n",
    "        if word in text:\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Create the new column\n",
    "data['dummy_label'] = data['message'].apply(lambda x: contains_word(x, gun_related_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "328e0387",
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_code = data[data['dummy_label'] == 1]\n",
    "no_gun_code = data[data['dummy_label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cc9fcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gun_code_sample=gun_code[:1000]\n",
    "no_gun_code_sample = no_gun_code[:3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3e75e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = data.sample(n=4000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0733d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.concat([gun_code_sample, no_gun_code_sample], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4f5e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               id  \\\n",
      "72                              23842756757600772   \n",
      "114                             23842761814840048   \n",
      "327                             23843363987580262   \n",
      "337                                 6102775332336   \n",
      "348    hyperfeed_story_id_5c94f1dae77c55922092556   \n",
      "...                                           ...   \n",
      "35776                           23842797121080141   \n",
      "35782                           23842974222350252   \n",
      "35783                           23842794823000141   \n",
      "35784                           23842722359490239   \n",
      "35788                           23842794106150141   \n",
      "\n",
      "                                                    html  political  \\\n",
      "72     <div class=\"_1dwg _1w_m _q7o\"><div class=\"_5g-...          0   \n",
      "114    <div class=\"_1dwg _1w_m _q7o\"><div class=\"_5g-...          0   \n",
      "327    <div class=\"_5pcr userContentWrapper\"><div cla...          0   \n",
      "337    <div class=\"_5pcr userContentWrapper\"><div cla...          0   \n",
      "348    <div class=\"_5pcr userContentWrapper\"><div cla...          2   \n",
      "...                                                  ...        ...   \n",
      "35776  <div class=\"_1dwg _1w_m _q7o\"><div class=\"_5g-...          2   \n",
      "35782  <div class=\"_1dwg _1w_m\"><div><span class=\"_47...          9   \n",
      "35783  <div class=\"_1dwg _1w_m _q7o\"><div class=\"_4r_...          5   \n",
      "35784  <div class=\"_1dwg _1w_m _q7o\"><div class=\"_5g-...          9   \n",
      "35788  <div class=\"_1dwg _1w_m\"><div><span class=\"_47...          5   \n",
      "\n",
      "       not_political                                   title  \\\n",
      "72                 0                              Fight Back   \n",
      "114                0                     Mayor Philip Levine   \n",
      "327                0                              Jon Tester   \n",
      "337                0                            Mic Dispatch   \n",
      "348                0                      Sandy Hook Promise   \n",
      "...              ...                                     ...   \n",
      "35776              0          March for Our lives - Not Guns   \n",
      "35782              0                            Julie Oliver   \n",
      "35783              0          March for Our lives - Not Guns   \n",
      "35784              0  Brady Campaign to Prevent Gun Violence   \n",
      "35788              0          March for Our lives - Not Guns   \n",
      "\n",
      "                                                 message  \\\n",
      "72     <p>We will no longer sit idly by while Paul Ry...   \n",
      "114    <p>What happened in <a class=\"_58cn\"><span cla...   \n",
      "327    <p>After so many out-of-state billionaires hav...   \n",
      "337    <p>3D printing is the latest battleground in t...   \n",
      "348    <p>BREAKING: Congress will vote on legislation...   \n",
      "...                                                  ...   \n",
      "35776  <p>On March 24, the kids and families of <a cl...   \n",
      "35782  <p>We just made the Democratic run-off! That m...   \n",
      "35783  <p>On March 24, the kids and families of <a cl...   \n",
      "35784  <p>67% of Americans believe we should ban assa...   \n",
      "35788  <p>On March 24, the kids and families of <a cl...   \n",
      "\n",
      "                                               thumbnail  \\\n",
      "72     https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "114    https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "327    https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "337    https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "348    https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "...                                                  ...   \n",
      "35776  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "35782  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "35783  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "35784  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "35788  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "\n",
      "                          created_at                     updated_at   lang  \\\n",
      "72     2018-02-25 22:36:57.386563+00   2018-02-26 02:19:29.14029+00  en-US   \n",
      "114    2018-02-26 00:53:25.499318+00  2018-02-26 00:53:25.499318+00  en-US   \n",
      "327    2018-10-28 19:32:49.937058+00  2018-10-30 21:24:52.592512+00  en-US   \n",
      "337    2018-08-24 23:18:23.657883+00  2018-08-25 15:44:33.512472+00  en-US   \n",
      "348    2019-03-22 14:32:05.144626+00  2019-03-22 17:07:23.585289+00  en-US   \n",
      "...                              ...                            ...    ...   \n",
      "35776  2018-03-09 02:14:03.310035+00  2018-03-09 02:50:12.093021+00  en-US   \n",
      "35782  2018-03-08 23:15:51.938611+00  2018-03-09 20:45:28.790352+00  en-US   \n",
      "35783  2018-03-08 23:02:06.669564+00  2018-03-09 20:45:30.115903+00  en-US   \n",
      "35784  2018-03-08 22:22:59.909098+00  2018-03-31 23:05:12.949847+00  en-US   \n",
      "35788   2018-03-08 20:00:42.33688+00  2018-03-09 03:12:10.167853+00  en-US   \n",
      "\n",
      "       ...                                            targets  \\\n",
      "72     ...                                                 []   \n",
      "114    ...                                                 []   \n",
      "327    ...  [{\"target\": \"Age\", \"segment\": \"18 and older\"},...   \n",
      "337    ...  [{\"target\": \"Age\", \"segment\": \"18 and older\"},...   \n",
      "348    ...                                                 []   \n",
      "...    ...                                                ...   \n",
      "35776  ...  [{\"target\": \"Age\", \"segment\": \"35 and older\"},...   \n",
      "35782  ...  [{\"target\": \"Age\", \"segment\": \"18 and older\"},...   \n",
      "35783  ...  [{\"target\": \"Age\", \"segment\": \"35 and older\"},...   \n",
      "35784  ...  [{\"target\": \"Age\", \"segment\": \"30 and older\"},...   \n",
      "35788  ...  [{\"target\": \"Age\", \"segment\": \"35 and older\"},...   \n",
      "\n",
      "                                   advertiser  \\\n",
      "72                                 Fight Back   \n",
      "114                       Mayor Philip Levine   \n",
      "327                                Jon Tester   \n",
      "337                              Mic Dispatch   \n",
      "348                                       NaN   \n",
      "...                                       ...   \n",
      "35776          March for Our lives - Not Guns   \n",
      "35782                            Julie Oliver   \n",
      "35783          March for Our lives - Not Guns   \n",
      "35784  Brady Campaign to Prevent Gun Violence   \n",
      "35788          March for Our lives - Not Guns   \n",
      "\n",
      "                                                entities  \\\n",
      "72     [{\"entity\": \"Paul Ryan's\", \"entity_type\": \"Per...   \n",
      "114    [{\"entity\": \"Florida\", \"entity_type\": \"Region\"...   \n",
      "327    [{\"entity\": \"Montana\", \"entity_type\": \"Region\"...   \n",
      "337                                                   []   \n",
      "348    [{\"entity\": \"Congress\", \"entity_type\": \"Organi...   \n",
      "...                                                  ...   \n",
      "35776  [{\"entity\": \"MarchForOurLives\", \"entity_type\":...   \n",
      "35782  [{\"entity\": \"Democrats\", \"entity_type\": \"Group...   \n",
      "35783  [{\"entity\": \"Washington DC\", \"entity_type\": \"R...   \n",
      "35784  [{\"entity\": \"Congress\", \"entity_type\": \"Organi...   \n",
      "35788  [{\"entity\": \"MarchForOurLives\", \"entity_type\":...   \n",
      "\n",
      "                                                    page  \\\n",
      "72                https://www.facebook.com/fightbackpac/   \n",
      "114          https://www.facebook.com/mayorphiliplevine/   \n",
      "327                  https://www.facebook.com/jontester/   \n",
      "337          https://www.facebook.com/ThisIsMicDispatch/   \n",
      "348           https://www.facebook.com/SandyHookPromise/   \n",
      "...                                                  ...   \n",
      "35776  https://www.facebook.com/March-for-Our-lives-N...   \n",
      "35782            https://www.facebook.com/JulieForTexas/   \n",
      "35783  https://www.facebook.com/March-for-Our-lives-N...   \n",
      "35784            https://www.facebook.com/bradycampaign/   \n",
      "35788  https://www.facebook.com/March-for-Our-lives-N...   \n",
      "\n",
      "                                              lower_page  \\\n",
      "72                https://www.facebook.com/fightbackpac/   \n",
      "114          https://www.facebook.com/mayorphiliplevine/   \n",
      "327                  https://www.facebook.com/jontester/   \n",
      "337          https://www.facebook.com/thisismicdispatch/   \n",
      "348           https://www.facebook.com/sandyhookpromise/   \n",
      "...                                                  ...   \n",
      "35776  https://www.facebook.com/march-for-our-lives-n...   \n",
      "35782            https://www.facebook.com/juliefortexas/   \n",
      "35783  https://www.facebook.com/march-for-our-lives-n...   \n",
      "35784            https://www.facebook.com/bradycampaign/   \n",
      "35788  https://www.facebook.com/march-for-our-lives-n...   \n",
      "\n",
      "                                              targetings  \\\n",
      "72                                                   NaN   \n",
      "114                                                  NaN   \n",
      "327    {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "337    {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "348                                                  NaN   \n",
      "...                                                  ...   \n",
      "35776  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "35782  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "35783  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "35784  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "35788  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "\n",
      "                paid_for_by targetedness listbuilding_fundraising_proba  \\\n",
      "72                      NaN          NaN                       0.999918   \n",
      "114                     NaN          NaN                       0.180651   \n",
      "327    Montanans for Tester          4.0                       1.000000   \n",
      "337                     Mic          4.0                            NaN   \n",
      "348      Sandy Hook Promise          NaN                       0.213271   \n",
      "...                     ...          ...                            ...   \n",
      "35776                   NaN          5.0                       0.649685   \n",
      "35782                   NaN          2.0                       0.375328   \n",
      "35783                   NaN          4.0                       0.598348   \n",
      "35784                   NaN          4.0                       0.250779   \n",
      "35788                   NaN          4.0                       0.598348   \n",
      "\n",
      "      dummy_label  \n",
      "72              1  \n",
      "114             1  \n",
      "327             1  \n",
      "337             1  \n",
      "348             1  \n",
      "...           ...  \n",
      "35776           1  \n",
      "35782           1  \n",
      "35783           1  \n",
      "35784           1  \n",
      "35788           1  \n",
      "\n",
      "[1000 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_222/1251915638.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  print(sample_df[data['dummy_label'] == 1])\n"
     ]
    }
   ],
   "source": [
    "print(sample_df[data['dummy_label'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47987fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the DataFrame to a CSV file\n",
    "#sample_df.to_csv('jack_handcode.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9453e67d",
   "metadata": {},
   "source": [
    "# Data Descriptive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04f928c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Documents: 162324\n",
      "Average Document Length (in words): 55.08601315886745\n",
      "\n",
      "Distribution of Document Lengths:\n",
      "count    162324.000000\n",
      "mean         55.086013\n",
      "std         103.500739\n",
      "min           1.000000\n",
      "25%          22.000000\n",
      "50%          36.000000\n",
      "75%          57.000000\n",
      "max        2976.000000\n",
      "Name: word_count, dtype: float64\n",
      "\n",
      "Balance of the Dataset:\n",
      "dummy_label\n",
      "0    0.972555\n",
      "1    0.027445\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Number of Documents\n",
    "num_documents = len(data)\n",
    "\n",
    "# Average Document Length (in terms of words)\n",
    "data['word_count'] = data['message'].apply(lambda x: len(str(x).split()))\n",
    "average_doc_length = data['word_count'].mean()\n",
    "\n",
    "# Distribution of Document Lengths\n",
    "doc_length_distribution = data['word_count'].describe()\n",
    "\n",
    "# Balance of the Dataset\n",
    "label_distribution = data['dummy_label'].value_counts(normalize=True)\n",
    "\n",
    "print(\"Number of Documents:\", num_documents)\n",
    "print(\"Average Document Length (in words):\", average_doc_length)\n",
    "print(\"\\nDistribution of Document Lengths:\")\n",
    "print(doc_length_distribution)\n",
    "print(\"\\nBalance of the Dataset:\")\n",
    "print(label_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46b4c85",
   "metadata": {},
   "source": [
    "# TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6319159e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words associated with gun legislation:\n",
      "gun: 238.4225606855614\n",
      "violence: 140.2045461840269\n",
      "congress: 103.94849943441567\n",
      "help: 99.16536413251045\n",
      "petition: 96.11251731509047\n",
      "pp: 92.72110110178767\n",
      "guns: 92.22281608193832\n",
      "people: 89.22734646432878\n",
      "sign: 88.34178056687114\n",
      "make: 86.0165474003404\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "import re\n",
    "\n",
    "# Filter documents related to gun legislation\n",
    "gun_legislation_messages = [data['message'][i] for i, label in enumerate(data['dummy_label']) if label == 1]\n",
    "\n",
    "# Custom function for text cleaning\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra whitespaces\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Create TF-IDF vectorizer with text cleaning and stop words removal\n",
    "vectorizer = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS, preprocessor=clean_text)\n",
    "\n",
    "# Fit and transform the documents\n",
    "tfidf_matrix = vectorizer.fit_transform(gun_legislation_messages)\n",
    "\n",
    "# Get feature names (words)\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# Sum TF-IDF scores for each word across documents\n",
    "word_scores = tfidf_matrix.sum(axis=0)\n",
    "\n",
    "# Sort the words by TF-IDF score in descending order\n",
    "sorted_word_indices = word_scores.argsort()[0, ::-1]\n",
    "\n",
    "# Display the top words associated with gun legislation\n",
    "print(\"Top words associated with gun legislation:\")\n",
    "for i in range(10):  # Display top 10 words\n",
    "    word_index = sorted_word_indices[0, i]\n",
    "    word = feature_names[word_index]\n",
    "    score = word_scores[0, word_index]\n",
    "    print(f\"{word}: {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d44cd55",
   "metadata": {},
   "source": [
    "# LDA\n",
    "Need to remove the html elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad305186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words for each topic:\n",
      "Topic 0:\n",
      "people, pp, gun, time, day, violence, class_afxspan, class_cl, _afzspanspan, world\n",
      "Topic 1:\n",
      "gun, help, violence, pp, congress, guns, petition, need, make, background\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Create CountVectorizer with text cleaning and stop words removal\n",
    "vectorizer = CountVectorizer(stop_words=ENGLISH_STOP_WORDS, preprocessor=clean_text)\n",
    "\n",
    "# Fit and transform the documents\n",
    "X = vectorizer.fit_transform(gun_legislation_messages)\n",
    "\n",
    "# Perform LDA\n",
    "lda = LatentDirichletAllocation(n_components=2, random_state=42)  # Change n_components as needed\n",
    "lda.fit(X)\n",
    "\n",
    "# Display the top words for each topic\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "print(\"Top words for each topic:\")\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(f\"Topic {topic_idx}:\")\n",
    "    top_words_indices = topic.argsort()[:-11:-1]  # Display top 10 words\n",
    "    top_words = [feature_names[i] for i in top_words_indices]\n",
    "    print(\", \".join(top_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5970d6",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b3d1d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jandolina/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment analysis results:\n",
      "                                                id  \\\n",
      "0       hyperfeed_story_id_5c9baa3ee0ec08073500042   \n",
      "1       hyperfeed_story_id_5c9bb2a2413852086735771   \n",
      "2       hyperfeed_story_id_5c9bb4fa461731e29426627   \n",
      "3                                23843380741530360   \n",
      "4       hyperfeed_story_id_5c9bb059454851c17741213   \n",
      "...                                            ...   \n",
      "162319                           23843108782710078   \n",
      "162320                           23843034525850259   \n",
      "162321                           23842997138670612   \n",
      "162322  hyperfeed_story_id_5c8b16b11b8f86515960964   \n",
      "162323                           23842885237930242   \n",
      "\n",
      "                                                     html  political  \\\n",
      "0       <div class=\"_5pa- userContentWrapper\"><div cla...          0   \n",
      "1       <div class=\"_5pa- userContentWrapper\"><div cla...          0   \n",
      "2       <div class=\"_5pa- userContentWrapper\"><div cla...          0   \n",
      "3       <div class=\"_5pcr userContentWrapper\"><div cla...          0   \n",
      "4       <div class=\"_5pa- userContentWrapper\"><div cla...          0   \n",
      "...                                                   ...        ...   \n",
      "162319  <div class=\"_5pcr userContentWrapper\"><div cla...         12   \n",
      "162320  <div class=\"_5pcr userContentWrapper\"><div cla...          0   \n",
      "162321  <div class=\"_5pcr userContentWrapper\"><div cla...          0   \n",
      "162322  <div class=\"_5pa- userContentWrapper\"><div cla...          7   \n",
      "162323  <div class=\"_5pcr userContentWrapper\"><div cla...          0   \n",
      "\n",
      "        not_political                                        title  \\\n",
      "0                   0                League of Conservation Voters   \n",
      "1                   0                            Indivisible Guide   \n",
      "2                   0               International Rescue Committee   \n",
      "3                   0                 Covenant House International   \n",
      "4                   1                           Planned Parenthood   \n",
      "...               ...                                          ...   \n",
      "162319              0                        Keep Them Accountable   \n",
      "162320              0  National Republican Congressional Committee   \n",
      "162321              0                              POW Action Fund   \n",
      "162322              0                                Beto O'Rourke   \n",
      "162323              0                                         ACLU   \n",
      "\n",
      "                                                  message  \\\n",
      "0       <p>BREAKING: Trump’s Department of the Interio...   \n",
      "1       <p>The Mueller investigation is over. Special ...   \n",
      "2       <p>Zimbabwe is reeling from the impact of Cycl...   \n",
      "3       <p>What more can you do in the final hours of ...   \n",
      "4       <p>Say it loud, say it proud: Our rights, our ...   \n",
      "...                                                   ...   \n",
      "162319  <p>Rep. Katko voted for tax breaks for his wea...   \n",
      "162320  <p>Illinois early voting is open NOW &amp; you...   \n",
      "162321  <p>From your favorite peaks to the polling pla...   \n",
      "162322  <p>Beto just announced he’s running for presid...   \n",
      "162323  <p>Claim your FREE ACLU Voter sticker today to...   \n",
      "\n",
      "                                                thumbnail  \\\n",
      "0       https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "1       https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "2       https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "3       https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "4       https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "...                                                   ...   \n",
      "162319  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "162320  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "162321  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "162322  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "162323  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "\n",
      "                           created_at                     updated_at   lang  \\\n",
      "0       2019-03-27 16:52:25.625455+00  2019-03-27 16:52:25.625455+00  en-US   \n",
      "1       2019-03-27 17:28:14.096849+00  2019-03-27 17:28:14.096849+00  en-US   \n",
      "2       2019-03-27 17:38:23.101377+00  2019-03-27 17:38:23.101377+00  en-US   \n",
      "3       2018-12-30 20:59:13.879124+00  2018-12-30 20:59:13.879124+00  en-US   \n",
      "4       2019-03-27 17:18:29.764002+00  2019-04-11 15:02:58.081112+00  en-US   \n",
      "...                               ...                            ...    ...   \n",
      "162319  2018-10-19 10:31:52.466563+00   2018-10-22 11:40:06.24382+00  en-US   \n",
      "162320  2018-10-24 20:41:42.111865+00  2018-10-24 20:41:42.111865+00  en-US   \n",
      "162321   2018-10-09 20:03:32.81012+00   2018-10-09 20:03:32.81012+00  en-US   \n",
      "162322  2019-03-15 03:07:40.590249+00   2019-03-22 17:01:05.36319+00  en-US   \n",
      "162323  2018-08-08 02:54:51.076959+00  2018-08-08 20:03:36.302904+00  en-US   \n",
      "\n",
      "        ...                                               page  \\\n",
      "0       ...                 https://www.facebook.com/LCVoters/   \n",
      "1       ...         https://www.facebook.com/indivisibleguide/   \n",
      "2       ...  https://www.facebook.com/InternationalRescueCo...   \n",
      "3       ...            https://www.facebook.com/CovenantHouse/   \n",
      "4       ...        https://www.facebook.com/PlannedParenthood/   \n",
      "...     ...                                                ...   \n",
      "162319  ...    https://www.facebook.com/KeepThemAccountable18/   \n",
      "162320  ...                     https://www.facebook.com/NRCC/   \n",
      "162321  ...            https://www.facebook.com/POWActionFund/   \n",
      "162322  ...              https://www.facebook.com/betoorourke/   \n",
      "162323  ...                     https://www.facebook.com/aclu/   \n",
      "\n",
      "                                               lower_page  \\\n",
      "0                      https://www.facebook.com/lcvoters/   \n",
      "1              https://www.facebook.com/indivisibleguide/   \n",
      "2       https://www.facebook.com/internationalrescueco...   \n",
      "3                 https://www.facebook.com/covenanthouse/   \n",
      "4             https://www.facebook.com/plannedparenthood/   \n",
      "...                                                   ...   \n",
      "162319    https://www.facebook.com/keepthemaccountable18/   \n",
      "162320                     https://www.facebook.com/nrcc/   \n",
      "162321            https://www.facebook.com/powactionfund/   \n",
      "162322              https://www.facebook.com/betoorourke/   \n",
      "162323                     https://www.facebook.com/aclu/   \n",
      "\n",
      "                                               targetings  \\\n",
      "0                                                     NaN   \n",
      "1                                                     NaN   \n",
      "2                                                     NaN   \n",
      "3       {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "4                                                     NaN   \n",
      "...                                                   ...   \n",
      "162319  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "162320  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "162321  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "162322                                                NaN   \n",
      "162323  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...   \n",
      "\n",
      "                                              paid_for_by targetedness  \\\n",
      "0                           League of Conservation Voters          NaN   \n",
      "1                                     Indivisible Project          NaN   \n",
      "2                          International Rescue Committee          NaN   \n",
      "3                            Covenant House International          5.0   \n",
      "4                Planned Parenthood Federation of America          NaN   \n",
      "...                                                   ...          ...   \n",
      "162319  HOUSE MAJORITY PAC, (202) 849-6052, AND PRIORI...          7.0   \n",
      "162320  the NRCC and not authorized by any candidate o...          4.0   \n",
      "162321                    Protect Our Winters Action Fund          4.0   \n",
      "162322                                   Beto for America          NaN   \n",
      "162323                                           the ACLU          6.0   \n",
      "\n",
      "       listbuilding_fundraising_proba contains_word word_count dummy_label  \\\n",
      "0                            0.647945             0         37           0   \n",
      "1                            0.350635             0         78           0   \n",
      "2                            0.999909             0         34           0   \n",
      "3                                 NaN             0         20           0   \n",
      "4                            0.999977             0         19           0   \n",
      "...                               ...           ...        ...         ...   \n",
      "162319                       0.116965             0         14           0   \n",
      "162320                       0.312412             0         20           0   \n",
      "162321                       0.205220             0         35           0   \n",
      "162322                       0.999994             0         45           0   \n",
      "162323                       0.354132             0         21           0   \n",
      "\n",
      "       sentiment  \n",
      "0       Negative  \n",
      "1       Positive  \n",
      "2       Negative  \n",
      "3       Positive  \n",
      "4       Positive  \n",
      "...          ...  \n",
      "162319  Positive  \n",
      "162320   Neutral  \n",
      "162321  Positive  \n",
      "162322   Neutral  \n",
      "162323  Positive  \n",
      "\n",
      "[162324 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Initialize the sentiment analyzer\n",
    "nltk.download('vader_lexicon')  # Download the lexicon required for sentiment analysis\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Perform sentiment analysis for each message\n",
    "sentiments = []\n",
    "for message in data['message']:\n",
    "    sentiment_score = sid.polarity_scores(message)\n",
    "    # Classify sentiment based on compound score\n",
    "    if sentiment_score['compound'] >= 0.05:\n",
    "        sentiment = 'Positive'\n",
    "    elif sentiment_score['compound'] <= -0.05:\n",
    "        sentiment = 'Negative'\n",
    "    else:\n",
    "        sentiment = 'Neutral'\n",
    "    sentiments.append(sentiment)\n",
    "\n",
    "# Add the sentiment labels to the DataFrame\n",
    "data['sentiment'] = sentiments\n",
    "\n",
    "# Display the DataFrame with sentiment labels\n",
    "print(\"Sentiment analysis results:\")\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b213b4",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "591336d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1158/545778796.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the English NER model in spaCy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"en_core_web_sm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English NER model in spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Process the text with spaCy NER\n",
    "doc = nlp(text)\n",
    "\n",
    "# Function to perform Named Entity Recognition (NER) using spaCy\n",
    "def perform_ner(text):\n",
    "    doc = nlp(text)\n",
    "    named_entities = [(entity.text, entity.label_) for entity in doc.ents]\n",
    "    return named_entities\n",
    "\n",
    "# Apply NER to each text in the 'text' column\n",
    "data['named_entities'] = data['text'].apply(perform_ner)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
