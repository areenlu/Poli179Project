{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d1ab6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: 22536170_6076215151101_4297820202256564224_n.png\n",
      "Caption: a woman and child are sitting at a table with a laptop\n",
      "\n",
      "Image: 22536021_6080198483032_6892544425491169280_n.png\n",
      "Caption: should you be a fraud lawyer?\n",
      "\n",
      "Image: 22536308_23842807707020458_9145441238248325120_n.png\n",
      "Caption: a woman speaking into a microphone\n",
      "\n",
      "Image: 22536073_23842667387060404_6467826319454371840_n.png\n",
      "Caption: a white background with the words adyoume\n",
      "\n",
      "Image: 22536002_23842931826010130_5938507832566480896_n.png\n",
      "Caption: a man and woman sitting at a table\n",
      "\n",
      "Image: 22536127_6088530829541_1999850151564279808_n.png\n",
      "Caption: a man in a suit and tie holding a certificate\n",
      "\n",
      "Image: 22536238_6084008680274_5100947488534167552_n.png\n",
      "Caption: save our land - save our land\n",
      "\n",
      "Image: 22536023_6085200408546_2992558544122806272_n.png\n",
      "Caption: the 2018 dmr membership card\n",
      "\n",
      "Image: 22536255_23842797186510697_5658114491829714944_n.png\n",
      "Caption: a woman wearing a hat\n",
      "\n",
      "Image: 22536279_23842689871060612_4597580684402360320_n.png\n",
      "Caption: a black and white photo with the words sign petition, protect whistles\n",
      "\n",
      "Image: 22536042_6080423825223_5471680363921145856_n.png\n",
      "Caption: a man in a suit and tie is speaking into a microphone\n",
      "\n",
      "Image: 22536288_6099990407796_7418361899852496896_n.png.jpg\n",
      "Caption: a dog is being examined by a vet\n",
      "\n",
      "Image: 22528437_291765441324942_5356440690133579662_n.jpg\n",
      "Caption: a man in a suit and tie holding a microphone\n",
      "\n",
      "Image: 22536168_6084080041389_7858698577151787008_n.png\n",
      "Caption: a bird standing in the grass\n",
      "\n",
      "Image: 22519928_10154845950756850_2624899290522465359_o.jpg\n",
      "Caption: a poster with the words 43 years fighting for hos\n",
      "\n",
      "Image: 22536128_6083197966791_1310667523015835648_n.png.jpg\n",
      "Caption: a house in the middle of a flooded street\n",
      "\n",
      "Image: 22528159_532178157126318_4957579883820628874_n.jpg\n",
      "Caption: a woman wearing a black shirt with a picture of a woman on it\n",
      "\n",
      "Image: 22536155_6075020457390_2522341869539557376_n.png\n",
      "Caption: a billboard with a picture of donald on it\n",
      "\n",
      "Image: 22536023_6082903165107_3665698932949778432_n.png.jpg\n",
      "Caption: a group of soldiers walking through a snow covered street\n",
      "\n",
      "Image: 22536101_6094278805076_3020201374546657280_n.png\n",
      "Caption: the city skyline with the words,'the most cities in the world are in los '\n",
      "\n",
      "Image: 22536187_23842706731390653_8812097547821645824_n.png\n",
      "Caption: a man in a suit and tie standing in front of a river\n",
      "\n",
      "Image: 22536201_6084206350805_2926097988256268288_n.png\n",
      "Caption: a person holding a fence with the words from school to prison\n",
      "\n",
      "Image: 22536346_23842626448010147_6276634780826075136_n.png\n",
      "Caption: a woman sitting on the floor in front of a wall\n",
      "\n",
      "Image: 22536124_6084572606515_8626919491688726528_n.png\n",
      "Caption: two hands in handcuffs\n",
      "\n",
      "Image: 22536322_23842636886590346_1976273774701445120_n.png\n",
      "Caption: a man talking to a woman in a blue shirt\n",
      "\n",
      "Image: 22536043_23842636127730609_8525738673604395008_n.png\n",
      "Caption: a man and woman are standing in front of a podium\n",
      "\n",
      "Image: 22536083_6089696728995_3687755226397278208_n.png\n",
      "Caption: a man sitting at a table with a laptop\n",
      "\n",
      "Image: 22536133_6090013883521_8903077286002032640_n.png\n",
      "Caption: the words,'5 years of superspy ', and a photo of a crowd of\n",
      "\n",
      "Image: 22536100_6073125007681_8062665122339880960_n.png\n",
      "Caption: a body of water\n",
      "\n",
      "Image: 22528408_10155953105107834_2114205514212692874_n.jpg\n",
      "Caption: a watermel with a slice of watermel on it\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BlipForConditionalGeneration, BlipProcessor\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Load model and processor\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"gospacedev/blip-image-captioning-base-bf16\")\n",
    "processor = BlipProcessor.from_pretrained(\"gospacedev/blip-image-captioning-base-bf16\")\n",
    "\n",
    "# Folder containing the images\n",
    "image_folder = \"Data/Images\"\n",
    "\n",
    "# Iterate over each image file in the folder\n",
    "for image_filename in os.listdir(image_folder):\n",
    "    image_path = os.path.join(image_folder, image_filename)\n",
    "    \n",
    "    try:\n",
    "        # Load image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        # Generate output\n",
    "        inputs = processor(image, return_tensors=\"pt\")\n",
    "        output = model.generate(**inputs)\n",
    "        result = processor.decode(output[0], skip_special_tokens=True)\n",
    "        \n",
    "        # Print results\n",
    "        print(f\"Image: {image_filename}\")\n",
    "        print(f\"Caption: {result}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not process image {image_filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04eb82b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22519572_10155289989544751_6320226996623100578_n.jpg\n",
      "22519660_10154827594931363_1726498070050821167_n.jpg\n",
      "22519928_10154845950756850_2624899290522465359_o.jpg\n",
      "22520060_810444179135264_382797502721693908_o.jpg\n",
      "22528159_532178157126318_4957579883820628874_n.jpg\n",
      "22528235_2087676058119966_8752064974442749943_n.png\n",
      "22528408_10155953105107834_2114205514212692874_n.jpg\n",
      "22528437_291765441324942_5356440690133579662_n.jpg\n",
      "22528548_10154827594876363_5983366238821133905_n.jpg\n",
      "22536002_23842931826010130_5938507832566480896_n.png\n",
      "22536021_6080198483032_6892544425491169280_n.png\n",
      "22536023_6082903165107_3665698932949778432_n.png\n",
      "22536023_6082903165107_3665698932949778432_n.png.jpg\n",
      "22536023_6085200408546_2992558544122806272_n.png\n",
      "22536030_23842660378650311_5400078934064758784_n.png\n",
      "22536042_6080423825223_5471680363921145856_n.png\n",
      "22536043_23842636127730609_8525738673604395008_n.png\n",
      "22536073_23842667387060404_6467826319454371840_n.png\n",
      "22536083_6089696728995_3687755226397278208_n.png\n",
      "22536100_6073125007681_8062665122339880960_n.png\n",
      "22536101_6094278805076_3020201374546657280_n.png\n",
      "22536124_6084572606515_8626919491688726528_n.png\n",
      "22536127_6088530829541_1999850151564279808_n.png\n",
      "22536128_6083197966791_1310667523015835648_n.png.jpg\n",
      "22536133_6090013883521_8903077286002032640_n.png\n",
      "22536135_23842667387090404_5887751292041822208_n.png\n",
      "22536155_6075020457390_2522341869539557376_n.png\n",
      "22536168_6084080041389_7858698577151787008_n.png\n",
      "22536169_6082868194527_1915480166188974080_n.png\n",
      "22536170_6076215151101_4297820202256564224_n.png\n",
      "22536187_23842706731390653_8812097547821645824_n.png\n",
      "22536201_6084206350805_2926097988256268288_n.png\n",
      "22536223_6095241393409_3497138959983575040_n.png\n",
      "22536238_6084008680274_5100947488534167552_n.png\n",
      "22536255_23842797186510697_5658114491829714944_n.png\n",
      "22536264_23842631647460538_1519897052408971264_n.png\n",
      "22536279_23842689871060612_4597580684402360320_n.png\n",
      "22536288_6099990407796_7418361899852496896_n.png.jpg\n",
      "22536308_23842807707020458_9145441238248325120_n.png\n",
      "22536322_23842636886590346_1976273774701445120_n.png\n",
      "22536333_6086246757286_3340927164022259712_n.jpg\n",
      "22536346_23842626448010147_6276634780826075136_n.png\n"
     ]
    }
   ],
   "source": [
    "ls 'Data/Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2669abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
