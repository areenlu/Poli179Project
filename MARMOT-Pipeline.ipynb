{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f99eb9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'MARMOT' already exists and is not an empty directory.\n",
      "/home/jandolina/teams/jack_areen_rubin/MARMOT\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (2.2.0)\n",
      "Requirement already satisfied: numpy in /home/jandolina/.local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.26.4)\n",
      "Collecting pathlib (from -r requirements.txt (line 3))\n",
      "  Using cached pathlib-1.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (3.4.2)\n",
      "Collecting sklearn (from -r requirements.txt (line 5))\n",
      "  Using cached sklearn-0.0.post12.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[15 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hrunning develop\n",
      "error: can't create or remove files in install directory\n",
      "\n",
      "The following error occurred while trying to add or remove files in the\n",
      "installation directory:\n",
      "\n",
      "    [Errno 13] Permission denied: '/opt/conda/lib/python3.9/site-packages/test-easy-install-1051.write-test'\n",
      "\n",
      "The installation directory you specified (via --install-dir, --prefix, or\n",
      "the distutils default setting) was:\n",
      "\n",
      "    /opt/conda/lib/python3.9/site-packages/\n",
      "\n",
      "Perhaps your account does not have write access to this directory?  If the\n",
      "installation directory is a system-owned directory, you may need to sign in\n",
      "as the administrator or \"root\" account.  If you do not have administrative\n",
      "access to this machine, you may wish to choose a different installation\n",
      "directory, preferably one that is listed in your PYTHONPATH environment\n",
      "variable.\n",
      "\n",
      "For information on other options, you may wish to consult the\n",
      "documentation at:\n",
      "\n",
      "  https://setuptools.readthedocs.io/en/latest/easy_install.html\n",
      "\n",
      "Please make the appropriate changes for your system and try again.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/patrickywu/MARMOT\n",
    "\n",
    "# Move into the cloned directory\n",
    "%cd MARMOT\n",
    "\n",
    "# Install the required Python packages\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Run the setup script to install the package in development mode\n",
    "!python setup.py develop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e8c20c",
   "metadata": {},
   "source": [
    "# Init of bert, image, marmot models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115eaec4",
   "metadata": {},
   "source": [
    "to init bert:\n",
    "(bert pipeline)\n",
    "bert_model\n",
    "\n",
    "to init marmot:\n",
    "bert_model, image_model\n",
    "\n",
    "to init binary trainer:\n",
    "marmot_model, train_dataset, validation_dataset, epochs, learning_rate, batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7032c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marmot.modules.bert_pipeline import bert_textcaption_pipeline\n",
    "\n",
    "# Initialize a BERT model\n",
    "bert_model = 'bert-base-uncased'\n",
    "\n",
    "# Create an instance of bert_textcaption_pipeline\n",
    "textcaption_pipeline = bert_textcaption_pipeline(bert_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63555058",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Some weights of BertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import resnet50\n",
    "from marmot.modules.image_transformer import image_transformer\n",
    "\n",
    "# Instantiate a pre-trained ResNet-50 model\n",
    "image_model = resnet50(pretrained=True)\n",
    "\n",
    "# Create an instance of the image_transformer class\n",
    "image_translator = image_transformer(bert_model, image_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d4bbdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['bert.encoder.layer.0.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.0.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.0.crossattention.output.dense.bias', 'bert.encoder.layer.0.crossattention.output.dense.weight', 'bert.encoder.layer.0.crossattention.self.key.bias', 'bert.encoder.layer.0.crossattention.self.key.weight', 'bert.encoder.layer.0.crossattention.self.query.bias', 'bert.encoder.layer.0.crossattention.self.query.weight', 'bert.encoder.layer.0.crossattention.self.value.bias', 'bert.encoder.layer.0.crossattention.self.value.weight', 'bert.encoder.layer.1.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.1.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.1.crossattention.output.dense.bias', 'bert.encoder.layer.1.crossattention.output.dense.weight', 'bert.encoder.layer.1.crossattention.self.key.bias', 'bert.encoder.layer.1.crossattention.self.key.weight', 'bert.encoder.layer.1.crossattention.self.query.bias', 'bert.encoder.layer.1.crossattention.self.query.weight', 'bert.encoder.layer.1.crossattention.self.value.bias', 'bert.encoder.layer.1.crossattention.self.value.weight', 'bert.encoder.layer.10.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.10.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.10.crossattention.output.dense.bias', 'bert.encoder.layer.10.crossattention.output.dense.weight', 'bert.encoder.layer.10.crossattention.self.key.bias', 'bert.encoder.layer.10.crossattention.self.key.weight', 'bert.encoder.layer.10.crossattention.self.query.bias', 'bert.encoder.layer.10.crossattention.self.query.weight', 'bert.encoder.layer.10.crossattention.self.value.bias', 'bert.encoder.layer.10.crossattention.self.value.weight', 'bert.encoder.layer.11.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.11.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.11.crossattention.output.dense.bias', 'bert.encoder.layer.11.crossattention.output.dense.weight', 'bert.encoder.layer.11.crossattention.self.key.bias', 'bert.encoder.layer.11.crossattention.self.key.weight', 'bert.encoder.layer.11.crossattention.self.query.bias', 'bert.encoder.layer.11.crossattention.self.query.weight', 'bert.encoder.layer.11.crossattention.self.value.bias', 'bert.encoder.layer.11.crossattention.self.value.weight', 'bert.encoder.layer.2.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.2.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.2.crossattention.output.dense.bias', 'bert.encoder.layer.2.crossattention.output.dense.weight', 'bert.encoder.layer.2.crossattention.self.key.bias', 'bert.encoder.layer.2.crossattention.self.key.weight', 'bert.encoder.layer.2.crossattention.self.query.bias', 'bert.encoder.layer.2.crossattention.self.query.weight', 'bert.encoder.layer.2.crossattention.self.value.bias', 'bert.encoder.layer.2.crossattention.self.value.weight', 'bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.3.crossattention.output.dense.bias', 'bert.encoder.layer.3.crossattention.output.dense.weight', 'bert.encoder.layer.3.crossattention.self.key.bias', 'bert.encoder.layer.3.crossattention.self.key.weight', 'bert.encoder.layer.3.crossattention.self.query.bias', 'bert.encoder.layer.3.crossattention.self.query.weight', 'bert.encoder.layer.3.crossattention.self.value.bias', 'bert.encoder.layer.3.crossattention.self.value.weight', 'bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.4.crossattention.output.dense.bias', 'bert.encoder.layer.4.crossattention.output.dense.weight', 'bert.encoder.layer.4.crossattention.self.key.bias', 'bert.encoder.layer.4.crossattention.self.key.weight', 'bert.encoder.layer.4.crossattention.self.query.bias', 'bert.encoder.layer.4.crossattention.self.query.weight', 'bert.encoder.layer.4.crossattention.self.value.bias', 'bert.encoder.layer.4.crossattention.self.value.weight', 'bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.5.crossattention.output.dense.bias', 'bert.encoder.layer.5.crossattention.output.dense.weight', 'bert.encoder.layer.5.crossattention.self.key.bias', 'bert.encoder.layer.5.crossattention.self.key.weight', 'bert.encoder.layer.5.crossattention.self.query.bias', 'bert.encoder.layer.5.crossattention.self.query.weight', 'bert.encoder.layer.5.crossattention.self.value.bias', 'bert.encoder.layer.5.crossattention.self.value.weight', 'bert.encoder.layer.6.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.6.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.6.crossattention.output.dense.bias', 'bert.encoder.layer.6.crossattention.output.dense.weight', 'bert.encoder.layer.6.crossattention.self.key.bias', 'bert.encoder.layer.6.crossattention.self.key.weight', 'bert.encoder.layer.6.crossattention.self.query.bias', 'bert.encoder.layer.6.crossattention.self.query.weight', 'bert.encoder.layer.6.crossattention.self.value.bias', 'bert.encoder.layer.6.crossattention.self.value.weight', 'bert.encoder.layer.7.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.7.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.7.crossattention.output.dense.bias', 'bert.encoder.layer.7.crossattention.output.dense.weight', 'bert.encoder.layer.7.crossattention.self.key.bias', 'bert.encoder.layer.7.crossattention.self.key.weight', 'bert.encoder.layer.7.crossattention.self.query.bias', 'bert.encoder.layer.7.crossattention.self.query.weight', 'bert.encoder.layer.7.crossattention.self.value.bias', 'bert.encoder.layer.7.crossattention.self.value.weight', 'bert.encoder.layer.8.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.8.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.8.crossattention.output.dense.bias', 'bert.encoder.layer.8.crossattention.output.dense.weight', 'bert.encoder.layer.8.crossattention.self.key.bias', 'bert.encoder.layer.8.crossattention.self.key.weight', 'bert.encoder.layer.8.crossattention.self.query.bias', 'bert.encoder.layer.8.crossattention.self.query.weight', 'bert.encoder.layer.8.crossattention.self.value.bias', 'bert.encoder.layer.8.crossattention.self.value.weight', 'bert.encoder.layer.9.crossattention.output.LayerNorm.bias', 'bert.encoder.layer.9.crossattention.output.LayerNorm.weight', 'bert.encoder.layer.9.crossattention.output.dense.bias', 'bert.encoder.layer.9.crossattention.output.dense.weight', 'bert.encoder.layer.9.crossattention.self.key.bias', 'bert.encoder.layer.9.crossattention.self.key.weight', 'bert.encoder.layer.9.crossattention.self.query.bias', 'bert.encoder.layer.9.crossattention.self.query.weight', 'bert.encoder.layer.9.crossattention.self.value.bias', 'bert.encoder.layer.9.crossattention.self.value.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from marmot.modules.marmot_pipeline import marmot\n",
    "\n",
    "#  Instantiate the marmot class from the marmot module\n",
    "marmot = marmot(bert_model=bert_model, image_model=image_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e8fd5f",
   "metadata": {},
   "source": [
    "# Create sample data for pipeline testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382f2284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#import text\n",
    "data = pd.read_csv('/home/jandolina/teams/jack_areen_rubin/Data/fbpac-ads-en-US.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e77481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'html', 'political', 'not_political', 'title', 'message',\n",
      "       'thumbnail', 'created_at', 'updated_at', 'lang', 'images',\n",
      "       'impressions', 'political_probability', 'targeting', 'suppressed',\n",
      "       'targets', 'advertiser', 'entities', 'page', 'lower_page', 'targetings',\n",
      "       'paid_for_by', 'targetedness', 'listbuilding_fundraising_proba'],\n",
      "      dtype='object')\n",
      "{https://pp-facebook-ads.s3.amazonaws.com/v/t45.1600-4/cp0/q90/spS444/p180x540/49331592_23843377427170360_6166817401984778240_n.png.jpg}\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)\n",
    "print(data.images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc655bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23843377427170360_6166817401984778240_n.png\n"
     ]
    }
   ],
   "source": [
    "import regex as re\n",
    "\n",
    "urls = [\n",
    "    \"https://pp-facebook-ads.s3.amazonaws.com/v/t45.1600-4/cp0/q90/spS444/p180x540/49331592_23843377427170360_6166817401984778240_n.png.jpg\",\n",
    "    # Add more URLs here if needed\n",
    "]\n",
    "\n",
    "# Regular expression pattern to extract the desired substring\n",
    "pattern = r'_([\\w-]+\\.png)'\n",
    "\n",
    "# Extract the desired substring for each URL\n",
    "for url in urls:\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        extracted_text = match.group(1)\n",
    "        print(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59833adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         55844308_6127288747297_3018113389080608768_n.p...\n",
      "1         55863114_23843220221260433_8886009863356809216...\n",
      "2                                          wPe6V5iq-og.png}\n",
      "3         49331592_23843377427170360_6166817401984778240...\n",
      "4                                          u7XTTygYX3C.png}\n",
      "                                ...                        \n",
      "162319                                     -PAXP-deijE.gif}\n",
      "162320                                     -PAXP-deijE.gif}\n",
      "162321    39894768_23842963973330612_6596145833291284480...\n",
      "162322    55273822_23843395989240769_6786027694657110016...\n",
      "162323    37622419_23842883857610242_2096369976649711616...\n",
      "Name: filename, Length: 162324, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define a function to extract the filename from the urls\n",
    "pattern = r'/([^/]+)$'\n",
    "def extract_filename(url):\n",
    "    match = re.search(pattern, url)\n",
    "    if match:\n",
    "        extracted_text = match.group(1)\n",
    "        return(extracted_text)\n",
    "    else:\n",
    "        return('ERROR')\n",
    "\n",
    "# Apply the function to the column\n",
    "data['filename'] = data['images'].apply(extract_filename)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(data.filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6658c93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "#import images\n",
    "folder_path = '/home/jandolina/teams/jack_areen_rubin/Data/Images'\n",
    "\n",
    "filename_list = []\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if os.path.isfile(os.path.join(folder_path, filename)):\n",
    "        filename_list.append(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88973133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "print(len(filename_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d1eee88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1031/474004382.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matching_rows['matched_local_path'] = ((folder_path + '/')+ (matching_rows['filename'].apply(get_matching_value)))\n"
     ]
    }
   ],
   "source": [
    "# Function to identify matches and extract the matching value\n",
    "def get_matching_value(filename):\n",
    "    for val in filename_list:\n",
    "        if val in filename:\n",
    "            return val\n",
    "    return None\n",
    "\n",
    "# Identify rows where 'filename' column matches values from the list\n",
    "matching_rows = data[data['filename'].apply(lambda x: any(val in x for val in filename_list))]\n",
    "\n",
    "# Create a new column 'matching_value' and assign the matching value to it\n",
    "matching_rows['matched_local_path'] = ((folder_path + '/')+ (matching_rows['filename'].apply(get_matching_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c8f42e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'html', 'political', 'not_political', 'title', 'message',\n",
      "       'thumbnail', 'created_at', 'updated_at', 'lang', 'images',\n",
      "       'impressions', 'political_probability', 'targeting', 'suppressed',\n",
      "       'targets', 'advertiser', 'entities', 'page', 'lower_page', 'targetings',\n",
      "       'paid_for_by', 'targetedness', 'listbuilding_fundraising_proba',\n",
      "       'filename', 'matched_local_path'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(matching_rows.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49568eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                id  \\\n",
      "10318                                6106619708591   \n",
      "15759                                6106619718791   \n",
      "23306                            23842636904200346   \n",
      "23535                                6083430034527   \n",
      "23569                                6081591643823   \n",
      "...                                            ...   \n",
      "103553  hyperfeed_story_id_5c92c060156622346947409   \n",
      "112147                           23842695844070311   \n",
      "134650  hyperfeed_story_id_5cb229e0174828116868542   \n",
      "145650                           23842645528590609   \n",
      "145690                           23842656358710646   \n",
      "\n",
      "                                                     html  political  \\\n",
      "10318   <div class=\"_5pcr userContentWrapper\"><div cla...          3   \n",
      "15759   <div class=\"_5pcr userContentWrapper\"><div cla...          5   \n",
      "23306   <div class=\"_1dwg _1w_m\"><div class=\"_4r_y\"><d...          2   \n",
      "23535   <div class=\"_1dwg _1w_m\"><div class=\"_4r_y\"><d...          0   \n",
      "23569   <div class=\"_1dwg _1w_m _q7o\"><div class=\"_4r_...          2   \n",
      "...                                                   ...        ...   \n",
      "103553  <div class=\"_5pa- userContentWrapper\"><div cla...          1   \n",
      "112147  <div class=\"_1dwg _1w_m _q7o\"><div class=\"_5g-...          4   \n",
      "134650  <div class=\"_5pa- userContentWrapper\"><div cla...          0   \n",
      "145650  <div class=\"_1dwg _1w_m _q7o\"><div class=\"_4r_...          0   \n",
      "145690  <div class=\"_1dwg _1w_m\"><div class=\"_5g-l\"><d...          3   \n",
      "\n",
      "        not_political                             title  \\\n",
      "10318               1                       Sierra Club   \n",
      "15759               0                       Sierra Club   \n",
      "23306               0        Dean Phillips for Congress   \n",
      "23535               0      UNHCR, the UN Refugee Agency   \n",
      "23569               0            Texas Democratic Party   \n",
      "...               ...                               ...   \n",
      "103553              0                               USO   \n",
      "112147              0                      Jason Kander   \n",
      "134650              1                               USO   \n",
      "145650              0                 Justice Democrats   \n",
      "145690              0  Maine Center for Economic Policy   \n",
      "\n",
      "                                                  message  \\\n",
      "10318   <p>With the recent extreme weather events -- h...   \n",
      "15759   <p>With the recent extreme weather events -- h...   \n",
      "23306   <p>If elected in 2018, I’d be 1 of only 7 memb...   \n",
      "23535   <p>More than 5 million Syrian refugees forced ...   \n",
      "23569   <p>Texas Republicans' “Show me your papers” la...   \n",
      "...                                                   ...   \n",
      "103553  <p>When winter snowstorms are raging in Afghan...   \n",
      "112147  <div class=\"mbs _5pbx\" id=\"js_7i\">You may know...   \n",
      "134650  <p>When winter snowstorms are raging in Afghan...   \n",
      "145650  <p>DNC Chair Tom Perez just purged high-rankin...   \n",
      "145690  <p>Yes on 4: A Bipartisan Solution to Protect ...   \n",
      "\n",
      "                                                thumbnail  \\\n",
      "10318   https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "15759   https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "23306   https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "23535   https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "23569   https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "...                                                   ...   \n",
      "103553  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "112147  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "134650  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "145650  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "145690  https://pp-facebook-ads.s3.amazonaws.com/v/t1....   \n",
      "\n",
      "                           created_at                     updated_at   lang  \\\n",
      "10318   2018-09-22 00:04:13.443177+00  2018-09-27 04:10:10.394425+00  en-US   \n",
      "15759   2018-09-23 16:58:59.116609+00  2018-09-29 12:58:19.444037+00  en-US   \n",
      "23306   2017-10-28 02:48:55.870448+00  2017-11-02 12:57:58.113741+00  en-US   \n",
      "23535   2017-11-02 18:52:01.808253+00  2017-11-02 18:52:01.808253+00  en-US   \n",
      "23569   2017-11-15 22:49:01.449137+00  2017-12-27 18:12:23.518374+00  en-US   \n",
      "...                               ...                            ...    ...   \n",
      "103553  2019-03-20 22:37:41.722713+00  2019-03-21 00:18:56.327721+00  en-US   \n",
      "112147  2018-03-07 19:43:01.360025+00    2018-03-09 15:41:34.6903+00  en-US   \n",
      "134650  2019-04-13 18:27:31.862184+00  2019-04-13 21:02:55.499792+00  en-US   \n",
      "145650  2017-11-29 22:13:08.732674+00  2017-11-29 22:13:08.732674+00  en-US   \n",
      "145690  2017-10-25 22:42:06.591487+00  2017-10-25 23:14:36.046864+00  en-US   \n",
      "\n",
      "        ...                        advertiser  \\\n",
      "10318   ...                       Sierra Club   \n",
      "15759   ...                       Sierra Club   \n",
      "23306   ...        Dean Phillips for Congress   \n",
      "23535   ...      UNHCR, the UN Refugee Agency   \n",
      "23569   ...            Texas Democratic Party   \n",
      "...     ...                               ...   \n",
      "103553  ...                               NaN   \n",
      "112147  ...                      Jason Kander   \n",
      "134650  ...                               NaN   \n",
      "145650  ...                 Justice Democrats   \n",
      "145690  ...  Maine Center for Economic Policy   \n",
      "\n",
      "                                                 entities  \\\n",
      "10318   [{\"entity\": \"Chicago\", \"entity_type\": \"Region\"...   \n",
      "15759   [{\"entity\": \"RSVP\", \"entity_type\": \"Person\"}, ...   \n",
      "23306   [{\"entity\": \"Congress\", \"entity_type\": \"Organi...   \n",
      "23535      [{\"entity\": \"Syrian\", \"entity_type\": \"Group\"}]   \n",
      "23569   [{\"entity\": \"Texans\", \"entity_type\": \"Group\"},...   \n",
      "...                                                   ...   \n",
      "103553  [{\"entity\": \"Americans\", \"entity_type\": \"Group...   \n",
      "112147                                                 []   \n",
      "134650  [{\"entity\": \"Americans\", \"entity_type\": \"Group...   \n",
      "145650  [{\"entity\": \"Keith Ellison\", \"entity_type\": \"P...   \n",
      "145690  [{\"entity\": \"A Bipartisan Solution to Protect ...   \n",
      "\n",
      "                                                     page  \\\n",
      "10318                https://www.facebook.com/SierraClub/   \n",
      "15759                https://www.facebook.com/SierraClub/   \n",
      "23306   https://www.facebook.com/deanphillipsforcongress/   \n",
      "23535                     https://www.facebook.com/UNHCR/   \n",
      "23569      https://www.facebook.com/TexasDemocraticParty/   \n",
      "...                                                   ...   \n",
      "103553                   https://www.facebook.com/theUSO/   \n",
      "112147              https://www.facebook.com/jasonkander/   \n",
      "134650                   https://www.facebook.com/theUSO/   \n",
      "145650         https://www.facebook.com/justicedemocrats/   \n",
      "145690                   https://www.facebook.com/mecep1/   \n",
      "\n",
      "                                               lower_page  \\\n",
      "10318                https://www.facebook.com/sierraclub/   \n",
      "15759                https://www.facebook.com/sierraclub/   \n",
      "23306   https://www.facebook.com/deanphillipsforcongress/   \n",
      "23535                     https://www.facebook.com/unhcr/   \n",
      "23569      https://www.facebook.com/texasdemocraticparty/   \n",
      "...                                                   ...   \n",
      "103553                   https://www.facebook.com/theuso/   \n",
      "112147              https://www.facebook.com/jasonkander/   \n",
      "134650                   https://www.facebook.com/theuso/   \n",
      "145650         https://www.facebook.com/justicedemocrats/   \n",
      "145690                   https://www.facebook.com/mecep1/   \n",
      "\n",
      "                                               targetings  paid_for_by  \\\n",
      "10318   {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...  Sierra Club   \n",
      "15759   {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...  Sierra Club   \n",
      "23306   {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...          NaN   \n",
      "23535   {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...          NaN   \n",
      "23569   {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...          NaN   \n",
      "...                                                   ...          ...   \n",
      "103553                                                NaN      the USO   \n",
      "112147  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...          NaN   \n",
      "134650                                                NaN      the USO   \n",
      "145650  {\"<div><div class=\\\"_4-i0 _26c5\\\"><div class=\\...          NaN   \n",
      "145690                                                NaN          NaN   \n",
      "\n",
      "       targetedness listbuilding_fundraising_proba  \\\n",
      "10318           6.0                       0.149693   \n",
      "15759           3.0                       0.166995   \n",
      "23306           7.0                       0.476530   \n",
      "23535           4.0                       1.000038   \n",
      "23569           7.0                       0.305509   \n",
      "...             ...                            ...   \n",
      "103553          NaN                       0.264006   \n",
      "112147          5.0                       0.397937   \n",
      "134650          NaN                       0.264006   \n",
      "145650          1.0                       0.492939   \n",
      "145690          NaN                       0.696452   \n",
      "\n",
      "                                                 filename  \\\n",
      "10318   22536128_6083197966791_1310667523015835648_n.p...   \n",
      "15759   22536128_6083197966791_1310667523015835648_n.p...   \n",
      "23306   22536322_23842636886590346_1976273774701445120...   \n",
      "23535   22536169_6082868194527_1915480166188974080_n.png}   \n",
      "23569   22536042_6080423825223_5471680363921145856_n.png}   \n",
      "...                                                   ...   \n",
      "103553  22536023_6082903165107_3665698932949778432_n.p...   \n",
      "112147  22536030_23842660378650311_5400078934064758784...   \n",
      "134650  22536023_6082903165107_3665698932949778432_n.p...   \n",
      "145650  22536043_23842636127730609_8525738673604395008...   \n",
      "145690  22519572_10155289989544751_6320226996623100578...   \n",
      "\n",
      "                                       matched_local_path  \n",
      "10318   /home/jandolina/teams/jack_areen_rubin/Data/Im...  \n",
      "15759   /home/jandolina/teams/jack_areen_rubin/Data/Im...  \n",
      "23306   /home/jandolina/teams/jack_areen_rubin/Data/Im...  \n",
      "23535   /home/jandolina/teams/jack_areen_rubin/Data/Im...  \n",
      "23569   /home/jandolina/teams/jack_areen_rubin/Data/Im...  \n",
      "...                                                   ...  \n",
      "103553  /home/jandolina/teams/jack_areen_rubin/Data/Im...  \n",
      "112147  /home/jandolina/teams/jack_areen_rubin/Data/Im...  \n",
      "134650  /home/jandolina/teams/jack_areen_rubin/Data/Im...  \n",
      "145650  /home/jandolina/teams/jack_areen_rubin/Data/Im...  \n",
      "145690  /home/jandolina/teams/jack_areen_rubin/Data/Im...  \n",
      "\n",
      "[76 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(matching_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de60c1d",
   "metadata": {},
   "source": [
    "# Init binary data processing class\n",
    "\n",
    "Notes: why is caption_varname a parameter? whats the difference from text_varname? do I have to generate the captions first? Some errors shown in ID, badly collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc292a10",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1031/797173419.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  matching_rows['dummy_label'] = np.random.randint(2, size=len(matching_rows))\n",
      "/home/jandolina/teams/jack_areen_rubin/MARMOT/marmot/data/binary_data_processing.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data['pic'] = 1\n"
     ]
    }
   ],
   "source": [
    "from marmot.data.binary_data_processing import TextImageDatasetBinary\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "matching_rows.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# dummy label data\n",
    "matching_rows['dummy_label'] = np.random.randint(2, size=len(matching_rows))\n",
    "\n",
    "\n",
    "text_image_dataset = TextImageDatasetBinary(data = matching_rows , docid_varname = 'id', text_varname = 'message', \n",
    "                                            img_varname = 'matched_local_path', caption_varname = 'message', \n",
    "                                            label_varname = 'dummy_label', transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),  # Resize the image to a fixed size\n",
    "    transforms.ToTensor(),            # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize the image\n",
    "                                            ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa57a6f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>Celebrate America, the immigration nation, with our $11.90 value tasty Adobo and mouthwatering Pico Fruta offer! —<br> We outlaw wanting to be American, then complain only outlaws want to immigrate to America. Let's admit, at 1/7th the population density of Germany, there's still room for a steady stream of the world’s best and brightest, and those most in need of the equality that is our promise.</p><p> Yes, now more than ever, it's the time to celebrate all the goodness America's immi...</p>\n"
     ]
    }
   ],
   "source": [
    "print(text_image_dataset.__getitem__(10)['image_caption'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10c8e74",
   "metadata": {},
   "source": [
    "# Init text processor\n",
    "I think the image_captions need to be cleaned up. Right now these are just the text in the post, not image captions generated from the image. \n",
    "What does ii_text, tti_text, am_text represent?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "feb392af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marmot.data.text_processor import text_processor\n",
    "import torch\n",
    "\n",
    "text_processor = text_processor(bert_model, torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f81d0aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ii_text, tti_text, am_text = text_processor.extract_bert_inputs(text_image_dataset.__getitem__(10)['image_caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65a66f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  101,  1026,  1052,  1028,  8439,  2637,  1010,  1996,  7521,  3842,\n",
      "          1010,  2007,  2256,  1002,  2340,  1012,  3938,  3643, 11937, 21756,\n",
      "          4748, 16429,  2080,  1998,  2677,  5880,  2075, 27263,  2080, 10424,\n",
      "         13210,  3749,   999,  1517,  1026,  7987,  1028,  2057, 19104,  5782,\n",
      "          2000,  2022,  2137,  1010,  2059, 17612,  2069, 23107,  2215,  2000,\n",
      "         10047,  4328, 22780,  2000,  2637,  1012,  2292,  1005,  1055,  6449,\n",
      "          1010,  2012,  1015,  1013,  5504,  1996,  2313,  4304,  1997,  2762,\n",
      "          1010,  2045,  1005,  1055,  2145,  2282,  2005,  1037,  6706,  5460,\n",
      "          1997,  1996,  2088,  1521,  1055,  2190,  1998, 26849,  1010,  1998,\n",
      "          2216,  2087,  1999,  2342,  1997,  1996,  9945,  2008,  2003,  2256,\n",
      "          4872,  1012,  1026,  1013,  1052,  1028,  1026,  1052,  1028,  2748,\n",
      "          1010,  2085,  2062,  2084,  2412,  1010,  2009,  1005,  1055,  1996,\n",
      "          2051,  2000,  8439,  2035,  1996, 15003,  2637,  1005,  1055, 10047,\n",
      "          4328,  1012,  1012,  1012,  1026,  1013,  1052,  1028,   102]])\n",
      "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n",
      "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "print(ii_text)\n",
    "print(tti_text)\n",
    "print(am_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca49159",
   "metadata": {},
   "source": [
    "# BERT pipeline\n",
    "for now, just text. \n",
    "\n",
    "How do we interpret the output of forward? What does forward represent as a method?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88973e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from marmot.modules.bert_pipeline import bert_text_only_pipeline\n",
    "\n",
    "# Initialize a BERT model\n",
    "bert_model = 'bert-base-uncased'\n",
    "\n",
    "# Create an instance of bert_textcaption_pipeline\n",
    "text_only_pipeline = bert_text_only_pipeline(bert_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1c8be4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0735, -0.0036]], grad_fn=<AddmmBackward0>),\n",
       " BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0726, -0.0382,  0.1052,  ..., -0.4586,  0.3927,  0.2556],\n",
       "          [-0.4032,  0.4239,  0.2147,  ...,  1.1243,  0.4992, -0.1557],\n",
       "          [-0.1847, -0.0710,  1.5080,  ..., -0.2959, -0.3103,  1.4713],\n",
       "          ...,\n",
       "          [ 0.0864, -0.0776,  1.4545,  ..., -0.1966, -0.2054,  1.0998],\n",
       "          [ 0.4634, -0.2355,  0.2837,  ..., -0.0787, -0.4196, -0.0432],\n",
       "          [-0.1183,  0.7013,  0.4813,  ...,  0.3843, -0.3030, -0.3415]]],\n",
       "        grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.7820, -0.5764, -0.9856,  0.6752,  0.7592, -0.1525,  0.4791,  0.4677,\n",
       "          -0.9308, -1.0000, -0.5780,  0.9711,  0.9753,  0.8322,  0.8037, -0.4479,\n",
       "           0.2421, -0.5768,  0.4435,  0.7484,  0.7649,  1.0000, -0.2494,  0.3761,\n",
       "           0.6401,  0.9944, -0.7324,  0.8452,  0.9119,  0.6583, -0.2685,  0.3679,\n",
       "          -0.9845, -0.2544, -0.9930, -0.9828,  0.4803, -0.4012, -0.0899,  0.0696,\n",
       "          -0.7692,  0.2949,  1.0000,  0.3176,  0.6403, -0.1486, -1.0000,  0.3454,\n",
       "          -0.6447,  0.9765,  0.9498,  0.9867,  0.2647,  0.5720,  0.5020, -0.4167,\n",
       "          -0.0878,  0.0936, -0.3069, -0.5679, -0.6442,  0.6255, -0.9634, -0.8202,\n",
       "           0.9547,  0.9571, -0.3347, -0.4731, -0.1684, -0.1626,  0.6200,  0.3095,\n",
       "          -0.6829, -0.8904,  0.8720,  0.3151, -0.7316,  1.0000, -0.1996, -0.9533,\n",
       "           0.9772,  0.9174,  0.6420, -0.6289,  0.8285, -1.0000,  0.5226, -0.0960,\n",
       "          -0.9766,  0.4243,  0.6431, -0.2317,  0.9686,  0.6692, -0.4898, -0.6386,\n",
       "          -0.3016, -0.9511, -0.5564, -0.6168,  0.3245, -0.2578, -0.4949, -0.4338,\n",
       "           0.4814, -0.5567, -0.1615,  0.7421,  0.1223,  0.7156,  0.5303, -0.5021,\n",
       "           0.5090, -0.8918,  0.5922, -0.4181, -0.9741, -0.6837, -0.9836,  0.5255,\n",
       "          -0.4427, -0.3620,  0.8028, -0.8271,  0.4612, -0.3110, -0.9762, -1.0000,\n",
       "          -0.7198, -0.7207, -0.3783, -0.4294, -0.9561, -0.9453,  0.6471,  0.8801,\n",
       "           0.2412,  0.9999, -0.3881,  0.8991, -0.3869, -0.7676,  0.8310, -0.5785,\n",
       "           0.9231, -0.4293, -0.0982,  0.1788, -0.5320,  0.5960, -0.8290, -0.2677,\n",
       "          -0.9370, -0.8341, -0.4772,  0.8834, -0.7435, -0.9820, -0.3903, -0.2092,\n",
       "          -0.3700,  0.6664,  0.7529,  0.4563, -0.4744,  0.5873,  0.4184,  0.5376,\n",
       "          -0.6407, -0.3635,  0.3977, -0.3748, -0.9787, -0.9652, -0.4970,  0.4522,\n",
       "           0.9746,  0.4548,  0.3638,  0.8673, -0.3015,  0.7780, -0.9467,  0.9631,\n",
       "          -0.1586,  0.4598, -0.9207,  0.8104, -0.4474,  0.4784,  0.6423, -0.7932,\n",
       "          -0.5870, -0.2296, -0.5518, -0.3776, -0.9484,  0.1601, -0.3021, -0.4024,\n",
       "          -0.4222,  0.8766,  0.7250,  0.3899,  0.7085,  0.6260, -0.6489, -0.5307,\n",
       "           0.1375,  0.3126,  0.2510,  0.9768, -0.8977,  0.0461, -0.8486, -0.9791,\n",
       "          -0.0490, -0.7516, -0.3651, -0.6842,  0.8078, -0.7567,  0.5453,  0.5402,\n",
       "          -0.3955, -0.6574,  0.3792, -0.6376,  0.5798, -0.3519,  0.9788,  0.9924,\n",
       "          -0.5912, -0.5815,  0.9569, -0.9853, -0.7412,  0.2280, -0.3460,  0.5851,\n",
       "          -0.6895,  0.9679,  0.9656,  0.7186, -0.7923, -0.9414,  0.0649, -0.8338,\n",
       "          -0.1729,  0.5920,  0.9628,  0.6997,  0.4882,  0.0543, -0.6043,  0.7339,\n",
       "          -0.9806, -0.9211, -0.9403, -0.3238, -0.9827,  0.9582,  0.4527,  0.7289,\n",
       "          -0.5114, -0.6210, -0.8966,  0.4496,  0.2028,  0.8339, -0.6360, -0.7257,\n",
       "          -0.7443, -0.9053, -0.0409, -0.3411, -0.7616,  0.0716, -0.8002,  0.5844,\n",
       "           0.3799,  0.6031, -0.9723,  0.9859,  1.0000,  0.9292,  0.7236,  0.4957,\n",
       "          -1.0000, -0.8282,  1.0000, -0.9983, -1.0000, -0.7185, -0.5324,  0.1977,\n",
       "          -1.0000, -0.3414,  0.0105, -0.8115,  0.8608,  0.9381,  0.8594, -1.0000,\n",
       "           0.6496,  0.8022, -0.7001,  0.9739, -0.6186,  0.9458,  0.5939,  0.5096,\n",
       "          -0.2658,  0.6068, -0.9872, -0.7251, -0.8630, -0.9074,  0.9999,  0.1126,\n",
       "          -0.7790, -0.7511,  0.6836, -0.2565,  0.1499, -0.9325, -0.4156,  0.7142,\n",
       "           0.7438,  0.2444,  0.5057, -0.1767,  0.2383,  0.6535, -0.0375,  0.6709,\n",
       "          -0.9214, -0.1939, -0.5284,  0.1635, -0.8661, -0.9589,  0.9044, -0.4073,\n",
       "           0.9405,  1.0000,  0.7828, -0.4527,  0.7191,  0.1886, -0.8000,  1.0000,\n",
       "           0.9225, -0.9604, -0.6525,  0.8440, -0.6258, -0.7788,  0.9993, -0.2949,\n",
       "          -0.9119, -0.4180,  0.9755, -0.9832,  0.9997, -0.6756, -0.9516,  0.8915,\n",
       "           0.8744, -0.6318, -0.6566,  0.1659, -0.8568,  0.3556, -0.4975,  0.6015,\n",
       "           0.1279, -0.0404,  0.7451,  0.3826, -0.6605,  0.2655, -0.7702, -0.4992,\n",
       "           0.9861,  0.6366, -0.2683,  0.0616, -0.4162, -0.9074, -0.9268,  0.7024,\n",
       "           1.0000, -0.5334,  0.9410, -0.5296, -0.1826,  0.0784,  0.6315,  0.5931,\n",
       "          -0.3615, -0.7967,  0.9276, -0.6206, -0.9854,  0.2994,  0.3076, -0.2576,\n",
       "           1.0000,  0.5406,  0.3404,  0.6266,  0.9949,  0.0815,  0.0914,  0.9701,\n",
       "           0.9594, -0.3556,  0.6719,  0.1239, -0.9613, -0.5362, -0.6615,  0.1423,\n",
       "          -0.9315, -0.0759, -0.8917,  0.9134,  0.9888,  0.4733,  0.3622,  0.8891,\n",
       "           1.0000, -0.9717,  0.3159,  0.9431, -0.0602, -1.0000, -0.5911, -0.4026,\n",
       "          -0.0596, -0.9592, -0.4395,  0.3776, -0.8749,  0.9340,  0.8545, -0.8022,\n",
       "          -0.9664, -0.8637,  0.1949,  0.1620, -0.9985, -0.7175, -0.4096,  0.7487,\n",
       "          -0.4200, -0.8192, -0.4769, -0.3829,  0.5761, -0.3228,  0.7063,  0.9547,\n",
       "           0.7561, -0.9479, -0.4516, -0.2520, -0.4951,  0.5500, -0.6268, -0.9757,\n",
       "          -0.2950,  1.0000, -0.6652,  0.9777,  0.5608,  0.1929, -0.3798,  0.2651,\n",
       "           0.9908,  0.3657, -0.9017, -0.9481,  0.9265, -0.4766,  0.6874,  0.8595,\n",
       "           0.9258,  0.6201,  0.8967,  0.1833, -0.0095,  0.0629,  0.9642, -0.1281,\n",
       "          -0.4776, -0.3069, -0.3046, -0.4263,  0.8557,  1.0000,  0.3905,  0.8177,\n",
       "          -0.9803, -0.9519, -0.6149,  1.0000,  0.8204, -0.0775,  0.6545,  0.7579,\n",
       "          -0.2294,  0.0127, -0.3042, -0.4046,  0.4235,  0.1437,  0.8682, -0.7151,\n",
       "          -0.9556, -0.5473,  0.3869, -0.8861,  1.0000, -0.6416, -0.4024, -0.4128,\n",
       "          -0.4058, -0.9827, -0.0593, -0.9463, -0.4355,  0.3382,  0.8922,  0.2847,\n",
       "          -0.7153, -0.6891,  0.9413,  0.7568, -0.9715, -0.8734,  0.9024, -0.9200,\n",
       "           0.7290,  1.0000,  0.3863,  0.5655,  0.2551, -0.2809,  0.4063, -0.7680,\n",
       "           0.5603, -0.8397, -0.3840, -0.3051,  0.3852, -0.1457, -0.8465,  0.4456,\n",
       "           0.2903, -0.6533, -0.7127, -0.1568,  0.4367,  0.7885, -0.4123, -0.1511,\n",
       "           0.1959, -0.0221, -0.8292, -0.5201, -0.5283, -1.0000,  0.3675, -1.0000,\n",
       "           0.8106,  0.5839, -0.2710,  0.7344,  0.7554,  0.8639, -0.4982, -0.9635,\n",
       "           0.3580,  0.7123, -0.3724, -0.5132, -0.5124,  0.4051, -0.0357,  0.4092,\n",
       "          -0.8931,  0.7388, -0.3043,  1.0000,  0.2157, -0.6074, -0.6171,  0.3355,\n",
       "          -0.2857,  1.0000, -0.0341, -0.8996,  0.6374, -0.7517, -0.7418,  0.4321,\n",
       "           0.0333, -0.7776, -0.9822,  0.7815,  0.0839, -0.7102,  0.7054, -0.4532,\n",
       "          -0.5672,  0.2327,  0.9737,  0.9698,  0.6159,  0.4662, -0.7289, -0.6762,\n",
       "           0.9381,  0.3980, -0.4821,  0.2466,  1.0000,  0.3481, -0.8603, -0.0915,\n",
       "          -0.7742, -0.2202, -0.7935,  0.4017,  0.4448,  0.8270, -0.4004,  0.8922,\n",
       "          -0.9644,  0.0986, -0.6944, -0.8367,  0.5108, -0.7683, -0.9690, -0.9669,\n",
       "           0.7794, -0.4381, -0.1020,  0.3600,  0.0995,  0.4245,  0.5014, -1.0000,\n",
       "           0.8875,  0.4988,  0.9682,  0.8790,  0.8049,  0.6841,  0.3453, -0.9457,\n",
       "          -0.6678, -0.3824, -0.2421,  0.4946,  0.7336,  0.7616,  0.5115, -0.4851,\n",
       "          -0.6388, -0.8715, -0.9255, -0.9854,  0.5025, -0.8206, -0.4054,  0.9283,\n",
       "           0.2198, -0.1247, -0.6884, -0.9595,  0.2700,  0.5776, -0.1585,  0.0480,\n",
       "           0.2204,  0.7049,  0.7089,  0.9729, -0.9685,  0.4021, -0.9206,  0.6030,\n",
       "           0.9474, -0.8989,  0.2048,  0.6316, -0.5479,  0.3260, -0.5071, -0.5273,\n",
       "           0.8739, -0.4481,  0.5166, -0.4854, -0.0972, -0.5232, -0.2366, -0.5517,\n",
       "          -0.7565,  0.7311,  0.0611,  0.7089,  0.9539, -0.1018, -0.4989, -0.2012,\n",
       "          -0.9058, -0.8434,  0.3863, -0.0874, -0.6189,  0.8605,  0.0143,  0.9814,\n",
       "           0.5173, -0.4146, -0.4145, -0.4749,  0.7172, -0.5828, -0.6771, -0.6159,\n",
       "           0.6032,  0.2861,  1.0000, -0.8913, -0.9595, -0.5771, -0.4467,  0.5663,\n",
       "          -0.6501, -1.0000,  0.3875, -0.8666,  0.9085, -0.7654,  0.9415, -0.7451,\n",
       "          -0.8280, -0.4977,  0.8777,  0.9017, -0.4759, -0.6524,  0.6199, -0.8234,\n",
       "           0.9895,  0.6815, -0.4181, -0.1053,  0.6952, -0.9081, -0.7002,  0.6469]],\n",
       "        grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=(tensor([[[[7.3977e-03, 4.2685e-03, 5.5159e-03,  ..., 4.0680e-03,\n",
       "            2.7616e-03, 2.2995e-02],\n",
       "           [7.0424e-03, 8.2283e-03, 4.7585e-03,  ..., 2.6773e-03,\n",
       "            7.4641e-03, 6.2845e-03],\n",
       "           [4.9457e-03, 1.7995e-02, 4.5550e-03,  ..., 2.8401e-03,\n",
       "            8.2931e-03, 5.5700e-03],\n",
       "           ...,\n",
       "           [4.8339e-03, 2.2182e-02, 5.7681e-03,  ..., 3.3077e-03,\n",
       "            9.2998e-03, 2.9000e-03],\n",
       "           [3.7779e-03, 6.9011e-03, 3.3794e-03,  ..., 2.5140e-03,\n",
       "            4.3528e-03, 5.0814e-03],\n",
       "           [1.5691e-02, 7.1628e-03, 6.1142e-03,  ..., 4.2329e-03,\n",
       "            6.1763e-03, 1.1512e-02]],\n",
       " \n",
       "          [[4.1358e-02, 5.8871e-04, 2.4612e-04,  ..., 2.9173e-04,\n",
       "            2.7703e-04, 3.5998e-04],\n",
       "           [1.1474e-02, 9.0449e-03, 1.0804e-02,  ..., 7.6206e-03,\n",
       "            2.0036e-02, 3.5773e-03],\n",
       "           [3.1934e-03, 2.6703e-02, 5.0109e-03,  ..., 2.5214e-03,\n",
       "            3.2647e-02, 9.9947e-03],\n",
       "           ...,\n",
       "           [2.9319e-03, 2.6568e-02, 4.3452e-03,  ..., 2.7605e-03,\n",
       "            5.0388e-02, 9.5269e-03],\n",
       "           [4.8037e-03, 2.1106e-02, 2.4523e-02,  ..., 1.8573e-02,\n",
       "            8.8533e-03, 2.4863e-03],\n",
       "           [2.7727e-03, 4.2826e-03, 2.4177e-03,  ..., 2.3875e-03,\n",
       "            7.3760e-03, 1.5041e-03]],\n",
       " \n",
       "          [[3.1821e-01, 7.6711e-03, 8.1926e-03,  ..., 4.9250e-03,\n",
       "            5.0473e-03, 1.4975e-02],\n",
       "           [7.8568e-01, 1.3408e-02, 1.0596e-02,  ..., 1.9755e-03,\n",
       "            1.8892e-03, 3.6604e-02],\n",
       "           [1.7519e-01, 4.2803e-01, 1.9472e-02,  ..., 7.7553e-03,\n",
       "            3.9204e-03, 3.7636e-03],\n",
       "           ...,\n",
       "           [1.0352e-02, 5.4375e-03, 4.6128e-04,  ..., 8.9333e-03,\n",
       "            7.8354e-03, 1.5382e-02],\n",
       "           [9.7412e-02, 1.3302e-02, 3.3433e-03,  ..., 2.6568e-01,\n",
       "            3.6277e-02, 7.9637e-02],\n",
       "           [6.9575e-02, 7.9195e-04, 4.8620e-03,  ..., 1.1985e-01,\n",
       "            3.1042e-01, 2.9294e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[8.2813e-03, 2.7103e-03, 9.9461e-03,  ..., 6.5835e-03,\n",
       "            2.5705e-03, 9.0892e-04],\n",
       "           [9.4758e-03, 2.9195e-02, 1.9329e-03,  ..., 2.4362e-03,\n",
       "            3.4667e-02, 1.7874e-02],\n",
       "           [1.4939e-02, 4.4195e-03, 4.9466e-02,  ..., 8.6626e-02,\n",
       "            3.3488e-03, 1.8530e-02],\n",
       "           ...,\n",
       "           [1.6542e-02, 6.2801e-03, 1.0623e-01,  ..., 7.1616e-02,\n",
       "            3.9628e-03, 1.2766e-02],\n",
       "           [1.2474e-02, 1.4965e-01, 5.3288e-04,  ..., 2.8172e-04,\n",
       "            2.1964e-02, 9.7587e-03],\n",
       "           [1.4531e-01, 1.8129e-02, 5.2437e-03,  ..., 2.1307e-03,\n",
       "            4.4757e-03, 4.8996e-03]],\n",
       " \n",
       "          [[3.2773e-01, 1.0517e-02, 8.2288e-03,  ..., 6.0391e-03,\n",
       "            2.9908e-03, 5.9895e-03],\n",
       "           [1.7790e-01, 2.7621e-02, 3.6038e-01,  ..., 1.8418e-02,\n",
       "            1.2881e-02, 1.1184e-02],\n",
       "           [5.3509e-03, 7.9722e-02, 3.7494e-02,  ..., 2.9253e-03,\n",
       "            3.1696e-03, 1.1049e-01],\n",
       "           ...,\n",
       "           [1.0641e-04, 2.1553e-04, 8.7804e-05,  ..., 5.1524e-03,\n",
       "            3.8529e-02, 8.9706e-01],\n",
       "           [1.4979e-02, 2.1684e-04, 6.2129e-05,  ..., 5.5187e-03,\n",
       "            1.1226e-02, 9.4712e-01],\n",
       "           [1.7512e-02, 4.2259e-03, 6.3662e-04,  ..., 1.0652e-01,\n",
       "            7.1002e-02, 5.9564e-01]],\n",
       " \n",
       "          [[4.9635e-01, 3.1257e-04, 1.4422e-03,  ..., 2.6630e-04,\n",
       "            4.0191e-05, 5.6489e-03],\n",
       "           [1.5969e-01, 2.4865e-02, 3.0199e-02,  ..., 7.9562e-03,\n",
       "            4.0958e-02, 3.1242e-02],\n",
       "           [1.0154e-02, 2.2940e-01, 7.6617e-03,  ..., 4.0349e-03,\n",
       "            4.0273e-02, 1.0175e-02],\n",
       "           ...,\n",
       "           [6.7121e-03, 6.1053e-02, 3.4836e-03,  ..., 1.1293e-02,\n",
       "            1.1179e-01, 3.4375e-02],\n",
       "           [1.3791e-01, 1.2029e-01, 1.5316e-03,  ..., 4.5599e-03,\n",
       "            3.6618e-02, 8.1243e-02],\n",
       "           [4.9042e-01, 5.1892e-03, 1.2587e-02,  ..., 3.1018e-02,\n",
       "            1.5504e-02, 1.2999e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.6070e-02, 1.1574e-03, 1.7138e-03,  ..., 2.8163e-03,\n",
       "            2.1902e-03, 2.0087e-03],\n",
       "           [3.4773e-03, 5.6314e-04, 1.2251e-03,  ..., 1.1431e-03,\n",
       "            1.8762e-02, 1.4185e-03],\n",
       "           [2.4923e-02, 1.4036e-02, 2.8567e-03,  ..., 1.3558e-03,\n",
       "            2.2700e-02, 2.0573e-02],\n",
       "           ...,\n",
       "           [2.7610e-02, 6.9928e-03, 2.0685e-03,  ..., 1.1699e-03,\n",
       "            1.9744e-02, 4.1853e-02],\n",
       "           [1.0322e-02, 3.4907e-04, 4.0166e-04,  ..., 3.5368e-04,\n",
       "            2.0895e-03, 3.1312e-03],\n",
       "           [1.0754e-01, 2.4334e-03, 3.0152e-03,  ..., 4.0473e-03,\n",
       "            5.3095e-03, 5.5143e-03]],\n",
       " \n",
       "          [[1.0427e-01, 1.2452e-02, 1.8908e-02,  ..., 7.7499e-03,\n",
       "            7.6460e-03, 2.3237e-02],\n",
       "           [2.8374e-01, 8.6797e-03, 6.4822e-01,  ..., 2.5660e-02,\n",
       "            1.9770e-03, 8.4729e-04],\n",
       "           [4.2397e-02, 1.3411e-03, 3.8147e-02,  ..., 6.7602e-04,\n",
       "            3.1633e-03, 5.5070e-03],\n",
       "           ...,\n",
       "           [3.1026e-02, 6.6291e-05, 1.3423e-03,  ..., 1.4636e-02,\n",
       "            7.6858e-01, 1.1959e-01],\n",
       "           [4.9710e-01, 1.0727e-04, 1.4606e-04,  ..., 2.6616e-03,\n",
       "            4.3616e-03, 4.8743e-01],\n",
       "           [7.6748e-01, 4.0999e-03, 1.6441e-04,  ..., 4.0809e-03,\n",
       "            3.0024e-03, 1.8226e-01]],\n",
       " \n",
       "          [[4.3260e-01, 3.2376e-03, 5.6089e-03,  ..., 7.0038e-03,\n",
       "            3.2852e-03, 1.7839e-02],\n",
       "           [3.7260e-02, 3.0009e-02, 2.9459e-02,  ..., 1.1013e-02,\n",
       "            2.1880e-02, 1.0429e-02],\n",
       "           [1.0032e-01, 2.1057e-02, 1.7381e-02,  ..., 3.5125e-03,\n",
       "            6.9400e-03, 5.5546e-03],\n",
       "           ...,\n",
       "           [2.4234e-01, 1.6987e-02, 1.4477e-02,  ..., 3.7263e-03,\n",
       "            6.5885e-03, 4.9337e-03],\n",
       "           [2.0047e-01, 3.3908e-02, 2.2574e-02,  ..., 8.4517e-03,\n",
       "            6.8737e-03, 1.3856e-02],\n",
       "           [4.9204e-01, 7.0428e-03, 7.4261e-03,  ..., 7.5908e-03,\n",
       "            2.4957e-03, 4.6321e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[3.8908e-02, 1.2287e-02, 5.6810e-03,  ..., 4.4561e-03,\n",
       "            6.1097e-03, 1.6815e-02],\n",
       "           [1.3947e-01, 1.7405e-03, 2.2416e-03,  ..., 1.5996e-03,\n",
       "            1.8069e-03, 2.5331e-02],\n",
       "           [6.3321e-02, 2.2990e-02, 5.2861e-04,  ..., 3.3223e-04,\n",
       "            4.7233e-03, 1.6873e-02],\n",
       "           ...,\n",
       "           [6.8747e-02, 1.4505e-02, 5.0518e-04,  ..., 3.7293e-04,\n",
       "            4.9618e-03, 2.2669e-02],\n",
       "           [1.3869e-01, 4.5607e-03, 2.3273e-03,  ..., 1.7739e-03,\n",
       "            1.2997e-03, 2.4890e-02],\n",
       "           [1.6969e-02, 7.2676e-03, 5.3167e-03,  ..., 5.6756e-03,\n",
       "            5.8701e-03, 1.6016e-02]],\n",
       " \n",
       "          [[2.5467e-01, 1.2589e-02, 7.0635e-03,  ..., 9.8336e-03,\n",
       "            1.1679e-02, 7.6078e-02],\n",
       "           [5.0518e-01, 2.3095e-02, 7.6325e-02,  ..., 1.0374e-02,\n",
       "            1.1707e-02, 2.7718e-02],\n",
       "           [5.0464e-01, 2.5727e-02, 3.1892e-02,  ..., 6.0346e-03,\n",
       "            1.1968e-02, 3.6832e-02],\n",
       "           ...,\n",
       "           [2.7514e-01, 1.3394e-02, 1.8658e-03,  ..., 1.5463e-02,\n",
       "            3.9952e-02, 1.3689e-01],\n",
       "           [3.5758e-01, 1.2515e-01, 1.1675e-02,  ..., 4.3060e-02,\n",
       "            8.8059e-03, 5.2035e-02],\n",
       "           [8.4958e-01, 3.3094e-03, 1.6393e-03,  ..., 1.5732e-02,\n",
       "            4.8101e-03, 5.8825e-02]],\n",
       " \n",
       "          [[5.3499e-02, 9.5035e-03, 3.3328e-03,  ..., 3.0167e-03,\n",
       "            7.4865e-03, 3.2689e-02],\n",
       "           [1.4226e-02, 3.4551e-02, 8.0178e-05,  ..., 9.1210e-05,\n",
       "            5.7179e-02, 6.5953e-03],\n",
       "           [6.2845e-03, 2.0890e-04, 1.4243e-01,  ..., 2.8970e-01,\n",
       "            1.8495e-04, 5.4073e-03],\n",
       "           ...,\n",
       "           [1.0577e-02, 7.8979e-04, 4.4376e-01,  ..., 8.2450e-02,\n",
       "            1.6013e-04, 7.3747e-03],\n",
       "           [9.9820e-03, 9.0085e-02, 1.3788e-04,  ..., 4.2951e-05,\n",
       "            4.7021e-02, 2.7363e-03],\n",
       "           [3.3994e-02, 1.1955e-02, 6.7405e-03,  ..., 5.1662e-03,\n",
       "            2.9691e-03, 1.1095e-02]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[9.5947e-01, 2.0380e-04, 9.0574e-05,  ..., 3.3709e-04,\n",
       "            4.8562e-04, 2.8752e-02],\n",
       "           [2.5473e-07, 1.4988e-06, 9.9987e-01,  ..., 5.8492e-08,\n",
       "            1.3686e-07, 5.0035e-10],\n",
       "           [7.6356e-07, 1.4691e-09, 1.1610e-06,  ..., 2.1041e-10,\n",
       "            1.5810e-06, 4.7075e-08],\n",
       "           ...,\n",
       "           [5.9293e-07, 1.0162e-15, 4.2693e-13,  ..., 1.1915e-06,\n",
       "            9.9998e-01, 1.5839e-05],\n",
       "           [4.2854e-05, 3.2397e-12, 1.1441e-13,  ..., 1.0589e-08,\n",
       "            1.4137e-06, 9.9995e-01],\n",
       "           [8.3476e-01, 5.4430e-05, 1.1561e-09,  ..., 8.4425e-06,\n",
       "            4.2637e-06, 1.6251e-01]],\n",
       " \n",
       "          [[6.8701e-01, 1.3243e-03, 1.2195e-03,  ..., 2.8431e-03,\n",
       "            1.3326e-03, 1.1757e-01],\n",
       "           [8.9396e-01, 9.3608e-04, 2.5089e-02,  ..., 5.6194e-03,\n",
       "            9.2806e-04, 4.2277e-02],\n",
       "           [3.5799e-01, 3.4356e-02, 2.0134e-04,  ..., 3.8076e-05,\n",
       "            4.8570e-02, 1.0578e-01],\n",
       "           ...,\n",
       "           [1.1055e-01, 1.0840e-02, 1.8835e-05,  ..., 4.0805e-04,\n",
       "            1.9211e-01, 1.9540e-01],\n",
       "           [2.4371e-02, 1.2247e-01, 1.1280e-02,  ..., 5.9171e-02,\n",
       "            5.6036e-03, 7.5298e-03],\n",
       "           [8.1536e-01, 6.0971e-04, 1.2371e-04,  ..., 1.6164e-03,\n",
       "            1.3529e-03, 1.4308e-01]],\n",
       " \n",
       "          [[5.6771e-01, 3.2077e-03, 1.3021e-03,  ..., 1.6415e-03,\n",
       "            1.0076e-03, 5.9279e-02],\n",
       "           [6.1269e-01, 6.2981e-03, 3.9940e-04,  ..., 1.2193e-03,\n",
       "            3.5747e-03, 3.0306e-02],\n",
       "           [5.5763e-01, 5.9866e-03, 6.9249e-05,  ..., 1.0060e-04,\n",
       "            1.9263e-03, 1.0912e-01],\n",
       "           ...,\n",
       "           [2.0723e-01, 1.4409e-02, 9.5498e-05,  ..., 9.4791e-05,\n",
       "            2.0866e-03, 1.4927e-01],\n",
       "           [5.9572e-01, 5.9095e-03, 4.0723e-04,  ..., 5.4687e-04,\n",
       "            2.0486e-04, 9.6973e-02],\n",
       "           [3.7648e-01, 6.6384e-03, 2.1383e-03,  ..., 3.1721e-03,\n",
       "            3.1777e-03, 7.2981e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[7.7931e-01, 2.6338e-03, 7.7525e-04,  ..., 4.4963e-04,\n",
       "            2.4438e-03, 8.7618e-02],\n",
       "           [2.8851e-07, 3.1464e-06, 9.9983e-01,  ..., 1.6279e-07,\n",
       "            2.4731e-07, 8.1496e-10],\n",
       "           [8.1235e-07, 1.4155e-09, 2.0440e-06,  ..., 9.2754e-11,\n",
       "            2.3616e-07, 3.7945e-08],\n",
       "           ...,\n",
       "           [4.3043e-05, 1.1915e-14, 3.5064e-12,  ..., 4.3267e-06,\n",
       "            9.9959e-01, 3.5250e-04],\n",
       "           [1.3510e-04, 1.9697e-12, 1.0958e-13,  ..., 1.4417e-08,\n",
       "            9.6707e-07, 9.9986e-01],\n",
       "           [9.6502e-01, 3.2463e-06, 5.0374e-11,  ..., 1.8873e-06,\n",
       "            1.4183e-06, 2.9923e-02]],\n",
       " \n",
       "          [[3.3389e-01, 5.2690e-03, 3.6648e-03,  ..., 4.2168e-03,\n",
       "            1.7555e-03, 6.2978e-02],\n",
       "           [2.5331e-01, 3.8312e-02, 8.6483e-03,  ..., 1.5889e-02,\n",
       "            1.8125e-02, 2.7606e-02],\n",
       "           [2.6868e-01, 2.3452e-02, 7.1811e-03,  ..., 1.1179e-02,\n",
       "            2.9928e-03, 2.8850e-02],\n",
       "           ...,\n",
       "           [1.8963e-01, 2.6271e-02, 1.0524e-02,  ..., 1.4764e-02,\n",
       "            2.8788e-03, 2.0909e-02],\n",
       "           [1.0055e-01, 2.2008e-01, 4.5612e-03,  ..., 5.8321e-03,\n",
       "            2.5944e-03, 4.0392e-03],\n",
       "           [6.2615e-01, 3.4187e-03, 2.9802e-03,  ..., 2.5812e-03,\n",
       "            8.4329e-04, 3.7004e-02]],\n",
       " \n",
       "          [[9.4757e-01, 3.4299e-04, 1.1681e-04,  ..., 4.1203e-04,\n",
       "            6.7805e-04, 1.1052e-02],\n",
       "           [2.8335e-01, 4.7937e-03, 2.4744e-02,  ..., 3.5913e-02,\n",
       "            1.9111e-02, 2.8357e-02],\n",
       "           [1.2377e-01, 1.4302e-02, 6.0432e-03,  ..., 1.2541e-03,\n",
       "            4.2277e-03, 5.4573e-03],\n",
       "           ...,\n",
       "           [3.1204e-01, 9.7164e-03, 3.6661e-03,  ..., 6.5526e-03,\n",
       "            1.2889e-02, 3.4634e-02],\n",
       "           [7.1232e-01, 1.8403e-03, 1.8808e-03,  ..., 1.4113e-02,\n",
       "            6.4012e-03, 6.7289e-02],\n",
       "           [9.8913e-01, 1.8512e-05, 1.0048e-05,  ..., 8.2947e-05,\n",
       "            1.0581e-04, 4.1249e-03]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.9457e-01, 8.0022e-04, 6.4244e-04,  ..., 1.2341e-03,\n",
       "            1.1625e-03, 3.2256e-01],\n",
       "           [4.9244e-04, 3.7863e-03, 3.2764e-06,  ..., 5.2991e-04,\n",
       "            5.0530e-03, 3.4241e-04],\n",
       "           [3.3759e-05, 8.5726e-06, 1.4614e-02,  ..., 3.4528e-01,\n",
       "            3.4321e-05, 1.4414e-05],\n",
       "           ...,\n",
       "           [5.4030e-04, 7.7847e-04, 6.9867e-01,  ..., 1.0525e-02,\n",
       "            2.3247e-05, 1.1109e-04],\n",
       "           [6.4977e-03, 2.6619e-02, 6.4588e-04,  ..., 5.8471e-05,\n",
       "            3.6409e-02, 1.5513e-03],\n",
       "           [2.7035e-01, 3.8313e-04, 2.3346e-04,  ..., 3.9680e-04,\n",
       "            7.3071e-04, 4.5106e-01]],\n",
       " \n",
       "          [[3.3959e-01, 6.5044e-03, 1.7005e-03,  ..., 3.1404e-03,\n",
       "            9.0152e-03, 4.2980e-01],\n",
       "           [2.2562e-01, 4.2373e-03, 5.7922e-03,  ..., 1.3924e-03,\n",
       "            2.3461e-03, 1.0028e-01],\n",
       "           [6.8038e-02, 1.3763e-02, 3.1717e-03,  ..., 8.8084e-04,\n",
       "            1.7418e-03, 5.1753e-02],\n",
       "           ...,\n",
       "           [5.5023e-02, 1.7185e-02, 3.4581e-03,  ..., 3.9334e-03,\n",
       "            8.6208e-03, 1.5484e-01],\n",
       "           [6.5442e-02, 4.5402e-03, 1.8848e-03,  ..., 3.9857e-03,\n",
       "            4.6151e-03, 8.0771e-01],\n",
       "           [4.4188e-01, 2.3419e-04, 4.4366e-04,  ..., 2.6432e-04,\n",
       "            1.5018e-04, 4.7273e-01]],\n",
       " \n",
       "          [[1.3896e-02, 9.9559e-03, 8.1674e-03,  ..., 3.9572e-03,\n",
       "            1.2289e-03, 2.6094e-02],\n",
       "           [3.3295e-01, 3.4506e-04, 6.1650e-03,  ..., 4.4075e-03,\n",
       "            7.2877e-04, 2.8949e-01],\n",
       "           [2.4244e-01, 4.8316e-03, 3.3211e-03,  ..., 2.5445e-03,\n",
       "            9.4612e-04, 2.5316e-01],\n",
       "           ...,\n",
       "           [3.4559e-01, 3.6136e-03, 1.4841e-03,  ..., 2.4018e-03,\n",
       "            2.9826e-03, 2.5561e-01],\n",
       "           [3.6065e-01, 1.5113e-03, 6.6798e-03,  ..., 8.7439e-03,\n",
       "            2.6027e-03, 1.5255e-01],\n",
       "           [1.0378e-01, 3.0548e-03, 1.5836e-03,  ..., 1.8770e-03,\n",
       "            9.2857e-04, 5.0821e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[6.6507e-01, 1.2987e-03, 6.4278e-04,  ..., 1.2517e-03,\n",
       "            6.8945e-03, 1.1730e-01],\n",
       "           [1.6794e-02, 1.9925e-03, 7.9530e-01,  ..., 1.1390e-03,\n",
       "            2.5768e-03, 1.1719e-02],\n",
       "           [1.4785e-02, 3.0063e-04, 8.8535e-04,  ..., 1.4232e-06,\n",
       "            3.2130e-04, 6.4237e-03],\n",
       "           ...,\n",
       "           [4.6773e-01, 4.8270e-06, 6.3243e-07,  ..., 4.6206e-04,\n",
       "            4.3239e-01, 8.7335e-02],\n",
       "           [9.0879e-01, 3.4455e-06, 1.9584e-07,  ..., 6.2025e-05,\n",
       "            4.6534e-03, 8.1738e-02],\n",
       "           [8.4105e-01, 7.8689e-04, 2.5118e-05,  ..., 5.5388e-05,\n",
       "            8.9268e-04, 5.0410e-02]],\n",
       " \n",
       "          [[2.9504e-01, 3.1994e-03, 1.2904e-03,  ..., 1.4201e-03,\n",
       "            9.7601e-04, 5.7999e-01],\n",
       "           [3.2030e-01, 9.3845e-03, 2.4059e-02,  ..., 2.4686e-02,\n",
       "            2.2738e-02, 2.4112e-01],\n",
       "           [1.4979e-01, 1.0953e-01, 4.3443e-02,  ..., 1.2576e-02,\n",
       "            1.1193e-02, 1.1298e-01],\n",
       "           ...,\n",
       "           [2.4051e-01, 3.7972e-02, 2.0753e-02,  ..., 2.4234e-02,\n",
       "            1.7528e-02, 2.6491e-01],\n",
       "           [3.8872e-01, 3.7908e-02, 1.9842e-02,  ..., 2.5021e-02,\n",
       "            1.2469e-02, 2.9597e-01],\n",
       "           [2.7857e-01, 1.8752e-04, 1.0017e-04,  ..., 1.2502e-04,\n",
       "            1.3326e-04, 6.8245e-01]],\n",
       " \n",
       "          [[5.9936e-01, 5.7791e-03, 1.3211e-03,  ..., 1.1493e-03,\n",
       "            2.7973e-03, 1.8291e-01],\n",
       "           [8.6515e-01, 4.7647e-03, 1.0086e-03,  ..., 1.0836e-05,\n",
       "            1.6597e-04, 9.3054e-02],\n",
       "           [5.5906e-01, 2.2923e-01, 3.0187e-03,  ..., 1.0755e-05,\n",
       "            9.6830e-05, 7.3738e-02],\n",
       "           ...,\n",
       "           [6.0393e-03, 1.2147e-03, 6.6817e-05,  ..., 9.6482e-03,\n",
       "            5.9011e-03, 1.6948e-02],\n",
       "           [1.3144e-02, 2.1582e-03, 1.0309e-04,  ..., 2.5111e-02,\n",
       "            1.2173e-02, 3.5526e-02],\n",
       "           [7.9613e-01, 4.5356e-04, 2.9804e-04,  ..., 4.7865e-04,\n",
       "            7.3801e-04, 1.6825e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[5.5908e-02, 2.2634e-03, 6.8874e-04,  ..., 1.6270e-03,\n",
       "            1.2908e-03, 7.1582e-01],\n",
       "           [7.8407e-03, 4.2270e-03, 4.7618e-03,  ..., 4.4236e-03,\n",
       "            6.1168e-02, 5.1139e-01],\n",
       "           [3.4066e-03, 2.0658e-02, 8.3978e-03,  ..., 3.9323e-03,\n",
       "            1.6446e-02, 1.7282e-01],\n",
       "           ...,\n",
       "           [4.2485e-03, 1.9197e-02, 1.0866e-02,  ..., 7.8839e-03,\n",
       "            1.9258e-02, 2.7569e-01],\n",
       "           [8.7592e-03, 7.6806e-03, 2.0576e-03,  ..., 1.4244e-03,\n",
       "            9.0171e-04, 8.7279e-01],\n",
       "           [7.2592e-02, 3.5949e-04, 1.1918e-04,  ..., 1.2487e-04,\n",
       "            2.8339e-04, 8.5192e-01]],\n",
       " \n",
       "          [[1.4771e-01, 3.6806e-02, 3.2150e-03,  ..., 4.9768e-03,\n",
       "            6.7155e-02, 1.8585e-03],\n",
       "           [2.8565e-03, 6.0406e-03, 4.4668e-03,  ..., 4.0291e-03,\n",
       "            1.1935e-02, 1.0817e-01],\n",
       "           [1.3817e-03, 3.9240e-03, 8.2050e-03,  ..., 6.4951e-03,\n",
       "            2.0230e-02, 1.7074e-01],\n",
       "           ...,\n",
       "           [2.8020e-04, 2.7180e-03, 1.3428e-02,  ..., 1.6541e-03,\n",
       "            1.1800e-03, 6.7085e-02],\n",
       "           [1.3964e-03, 3.7613e-03, 1.8430e-02,  ..., 4.2368e-03,\n",
       "            3.7855e-03, 3.7268e-02],\n",
       "           [2.7016e-02, 4.3270e-03, 4.9986e-03,  ..., 1.9532e-03,\n",
       "            3.6406e-03, 4.0002e-01]],\n",
       " \n",
       "          [[1.7234e-02, 2.1511e-02, 1.7163e-02,  ..., 2.2267e-02,\n",
       "            8.2371e-03, 2.7298e-02],\n",
       "           [2.9371e-02, 9.0459e-04, 3.1805e-03,  ..., 2.4341e-03,\n",
       "            3.9015e-04, 7.0276e-01],\n",
       "           [4.9906e-02, 2.5268e-03, 2.1047e-04,  ..., 1.1794e-04,\n",
       "            4.2875e-04, 6.9508e-01],\n",
       "           ...,\n",
       "           [1.1894e-01, 6.9221e-03, 2.2930e-04,  ..., 1.2411e-04,\n",
       "            1.2736e-03, 5.1983e-01],\n",
       "           [1.3843e-01, 3.9115e-03, 3.4209e-03,  ..., 3.5684e-03,\n",
       "            2.9148e-03, 4.9999e-01],\n",
       "           [6.8744e-02, 9.5399e-04, 1.3944e-03,  ..., 9.2262e-04,\n",
       "            1.2787e-03, 6.7128e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.1256e-02, 3.9367e-02, 5.0964e-03,  ..., 8.7850e-04,\n",
       "            2.8937e-03, 2.2729e-01],\n",
       "           [7.2826e-02, 2.7138e-02, 1.0944e-02,  ..., 2.3059e-03,\n",
       "            7.5508e-03, 3.9554e-01],\n",
       "           [6.6607e-02, 3.7769e-02, 1.7662e-02,  ..., 4.1373e-03,\n",
       "            7.5790e-03, 2.4993e-01],\n",
       "           ...,\n",
       "           [5.4893e-02, 2.0074e-02, 6.2016e-03,  ..., 2.5213e-02,\n",
       "            5.4354e-02, 2.2987e-01],\n",
       "           [5.2717e-02, 1.5909e-02, 2.3201e-03,  ..., 8.2414e-03,\n",
       "            3.0351e-02, 2.7742e-01],\n",
       "           [2.5579e-02, 9.9836e-04, 2.9948e-04,  ..., 4.6440e-04,\n",
       "            2.6226e-03, 7.8134e-01]],\n",
       " \n",
       "          [[8.7287e-03, 2.8230e-03, 7.4645e-04,  ..., 3.7933e-04,\n",
       "            1.3849e-03, 8.5262e-01],\n",
       "           [2.0084e-02, 1.6171e-02, 2.5638e-03,  ..., 1.1807e-05,\n",
       "            3.6227e-04, 9.4436e-01],\n",
       "           [3.3026e-02, 3.6943e-02, 6.0479e-03,  ..., 1.8399e-05,\n",
       "            3.2389e-04, 8.9238e-01],\n",
       "           ...,\n",
       "           [2.8907e-02, 6.9927e-04, 2.0741e-04,  ..., 4.4206e-02,\n",
       "            3.6931e-02, 2.8866e-01],\n",
       "           [1.6695e-02, 1.5077e-03, 2.6112e-04,  ..., 5.3604e-02,\n",
       "            5.9097e-02, 1.4311e-01],\n",
       "           [7.6483e-03, 9.8181e-04, 3.3629e-04,  ..., 5.3658e-04,\n",
       "            1.4274e-03, 9.2971e-01]],\n",
       " \n",
       "          [[2.7970e-02, 5.5426e-02, 1.3238e-02,  ..., 2.0867e-03,\n",
       "            1.3693e-02, 4.1505e-01],\n",
       "           [1.3632e-02, 6.9228e-03, 5.5790e-01,  ..., 2.1770e-03,\n",
       "            4.2052e-04, 3.7386e-01],\n",
       "           [2.5410e-03, 4.2037e-03, 4.2377e-03,  ..., 5.7451e-05,\n",
       "            7.4778e-03, 3.4552e-02],\n",
       "           ...,\n",
       "           [1.5233e-03, 2.8235e-04, 3.9140e-05,  ..., 6.1252e-03,\n",
       "            8.4977e-01, 7.5742e-02],\n",
       "           [5.9475e-03, 4.8253e-03, 4.5048e-04,  ..., 1.2603e-03,\n",
       "            5.7343e-02, 7.7357e-01],\n",
       "           [9.5718e-03, 2.3019e-03, 5.1065e-04,  ..., 3.5251e-04,\n",
       "            1.5186e-03, 7.9555e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.6435e-02, 5.9119e-02, 2.6285e-02,  ..., 6.2549e-04,\n",
       "            1.5587e-03, 5.5856e-01],\n",
       "           [7.8105e-03, 1.6416e-02, 2.2835e-02,  ..., 3.7260e-05,\n",
       "            7.2502e-04, 2.0625e-01],\n",
       "           [4.3446e-03, 5.9156e-03, 1.3177e-02,  ..., 3.4121e-05,\n",
       "            4.8606e-05, 7.7611e-01],\n",
       "           ...,\n",
       "           [3.8113e-03, 6.1394e-05, 1.7023e-04,  ..., 1.4627e-02,\n",
       "            1.1475e-02, 9.5591e-01],\n",
       "           [2.4508e-02, 4.0406e-04, 7.0213e-04,  ..., 2.3945e-03,\n",
       "            1.1527e-02, 9.5008e-01],\n",
       "           [1.5669e-02, 7.9241e-04, 8.0758e-04,  ..., 3.7401e-04,\n",
       "            5.1194e-04, 8.8859e-01]],\n",
       " \n",
       "          [[8.7003e-03, 5.6439e-04, 3.3629e-03,  ..., 6.2811e-03,\n",
       "            4.1448e-03, 8.1499e-01],\n",
       "           [4.3134e-04, 5.4753e-04, 1.2897e-03,  ..., 1.3238e-05,\n",
       "            1.7810e-05, 9.8646e-01],\n",
       "           [1.7930e-02, 1.2760e-01, 4.6986e-03,  ..., 1.7695e-05,\n",
       "            2.1073e-04, 7.1196e-01],\n",
       "           ...,\n",
       "           [2.9556e-02, 1.4688e-03, 1.2023e-04,  ..., 2.2467e-03,\n",
       "            6.0391e-03, 7.4063e-01],\n",
       "           [1.6210e-02, 6.1986e-05, 6.2692e-05,  ..., 1.4277e-02,\n",
       "            2.5411e-02, 8.7684e-01],\n",
       "           [6.7610e-03, 3.3664e-04, 2.5742e-04,  ..., 2.5278e-04,\n",
       "            2.0614e-04, 9.6077e-01]],\n",
       " \n",
       "          [[1.4028e-02, 6.6917e-03, 6.6919e-04,  ..., 6.0094e-03,\n",
       "            2.3080e-02, 5.8023e-01],\n",
       "           [1.1803e-02, 3.4616e-03, 9.5417e-04,  ..., 2.1736e-04,\n",
       "            2.9489e-04, 8.1705e-01],\n",
       "           [3.9979e-03, 8.4234e-03, 1.2406e-03,  ..., 5.3073e-04,\n",
       "            1.8810e-03, 7.4755e-01],\n",
       "           ...,\n",
       "           [2.5388e-02, 2.3049e-03, 4.3300e-04,  ..., 1.3331e-03,\n",
       "            7.4435e-03, 7.1954e-01],\n",
       "           [5.5856e-02, 2.8404e-03, 9.0084e-04,  ..., 1.8448e-03,\n",
       "            2.8203e-03, 7.7989e-01],\n",
       "           [1.7073e-02, 5.4373e-04, 7.6092e-04,  ..., 6.3096e-04,\n",
       "            3.1248e-04, 8.5339e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.9777e-02, 1.6260e-02, 5.8205e-03,  ..., 4.6970e-04,\n",
       "            2.4948e-03, 6.2665e-01],\n",
       "           [1.7766e-05, 2.5061e-02, 9.1201e-01,  ..., 6.0934e-04,\n",
       "            3.6837e-05, 1.8072e-02],\n",
       "           [9.6277e-07, 3.6716e-03, 1.5823e-03,  ..., 1.5768e-06,\n",
       "            4.2347e-04, 8.6891e-04],\n",
       "           ...,\n",
       "           [4.5753e-05, 1.8768e-05, 4.2845e-06,  ..., 5.3054e-03,\n",
       "            9.6292e-01, 1.7646e-02],\n",
       "           [1.2117e-02, 1.6825e-04, 9.5417e-06,  ..., 1.3173e-03,\n",
       "            1.9217e-02, 9.4317e-01],\n",
       "           [1.6998e-01, 3.2655e-04, 7.2964e-04,  ..., 7.7511e-04,\n",
       "            2.4055e-03, 5.9612e-01]],\n",
       " \n",
       "          [[1.1383e-02, 3.6399e-03, 6.3258e-04,  ..., 4.9687e-04,\n",
       "            6.3904e-03, 7.6643e-01],\n",
       "           [1.5118e-01, 1.4889e-02, 6.3470e-03,  ..., 6.6374e-06,\n",
       "            1.4998e-04, 8.1244e-01],\n",
       "           [1.0737e-01, 7.2112e-01, 3.6970e-02,  ..., 3.1286e-05,\n",
       "            1.0354e-04, 6.1938e-02],\n",
       "           ...,\n",
       "           [5.5296e-04, 6.1689e-04, 8.3621e-05,  ..., 1.9373e-02,\n",
       "            3.4012e-03, 1.2691e-02],\n",
       "           [7.3073e-04, 5.0981e-04, 1.2527e-04,  ..., 5.5707e-02,\n",
       "            4.2406e-02, 2.8606e-01],\n",
       "           [1.1483e-02, 1.4688e-03, 3.6471e-04,  ..., 4.7436e-04,\n",
       "            2.0032e-03, 8.1184e-01]],\n",
       " \n",
       "          [[4.1645e-02, 2.3070e-03, 9.6507e-04,  ..., 1.3477e-03,\n",
       "            6.9066e-03, 7.6982e-01],\n",
       "           [3.3293e-03, 4.2206e-02, 1.4178e-03,  ..., 2.5491e-05,\n",
       "            4.3456e-03, 1.5794e-02],\n",
       "           [4.0191e-03, 1.2676e-03, 1.2191e-03,  ..., 1.5222e-04,\n",
       "            4.9344e-04, 9.3427e-01],\n",
       "           ...,\n",
       "           [1.0838e-03, 3.3302e-06, 2.1031e-05,  ..., 9.9589e-04,\n",
       "            1.8064e-03, 9.8940e-01],\n",
       "           [1.2732e-02, 1.2368e-04, 4.3824e-05,  ..., 9.5641e-04,\n",
       "            3.5951e-03, 9.5431e-01],\n",
       "           [9.6985e-03, 1.1298e-03, 1.2092e-03,  ..., 2.5437e-03,\n",
       "            3.9190e-03, 7.6280e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[9.0092e-05, 3.0317e-03, 1.3513e-03,  ..., 2.2422e-02,\n",
       "            3.8964e-02, 6.9356e-03],\n",
       "           [3.1090e-03, 7.1004e-03, 1.3957e-03,  ..., 1.1642e-05,\n",
       "            2.9680e-05, 9.5849e-01],\n",
       "           [1.0258e-03, 5.1268e-04, 1.8557e-02,  ..., 2.2081e-04,\n",
       "            1.3230e-05, 9.4479e-01],\n",
       "           ...,\n",
       "           [6.1127e-04, 2.0191e-03, 4.6643e-02,  ..., 2.3628e-02,\n",
       "            1.6124e-03, 2.6558e-01],\n",
       "           [2.2438e-04, 7.0901e-04, 2.0422e-04,  ..., 1.4379e-03,\n",
       "            1.9582e-02, 1.1304e-01],\n",
       "           [2.9689e-03, 2.1779e-04, 4.2180e-04,  ..., 1.1441e-04,\n",
       "            2.2547e-04, 9.6843e-01]],\n",
       " \n",
       "          [[1.5568e-02, 2.0958e-02, 4.8495e-02,  ..., 2.4178e-03,\n",
       "            1.2031e-02, 4.8113e-02],\n",
       "           [2.1675e-01, 1.3318e-02, 1.4600e-02,  ..., 2.6289e-05,\n",
       "            1.0682e-03, 5.5460e-01],\n",
       "           [5.8605e-02, 1.5775e-01, 1.3219e-01,  ..., 3.0150e-04,\n",
       "            1.2277e-03, 4.6869e-01],\n",
       "           ...,\n",
       "           [7.0481e-03, 1.1734e-03, 3.5989e-03,  ..., 2.1883e-02,\n",
       "            5.3041e-02, 6.6876e-01],\n",
       "           [1.6487e-02, 2.9609e-03, 5.1591e-03,  ..., 2.6537e-02,\n",
       "            2.4512e-02, 4.4351e-01],\n",
       "           [5.2160e-03, 6.3604e-04, 8.6369e-04,  ..., 1.1789e-03,\n",
       "            1.2239e-03, 9.0773e-01]],\n",
       " \n",
       "          [[7.3707e-04, 1.4066e-03, 1.2525e-03,  ..., 1.2086e-02,\n",
       "            7.0410e-01, 3.5420e-02],\n",
       "           [7.3937e-03, 1.2785e-02, 4.1935e-03,  ..., 3.1508e-05,\n",
       "            1.1477e-03, 9.5039e-01],\n",
       "           [2.8665e-03, 3.1788e-02, 1.7713e-02,  ..., 1.7555e-04,\n",
       "            4.2327e-04, 9.2590e-01],\n",
       "           ...,\n",
       "           [4.8045e-04, 2.6416e-04, 8.9155e-04,  ..., 5.7942e-02,\n",
       "            3.1270e-02, 4.7031e-01],\n",
       "           [1.1796e-04, 2.7845e-04, 4.4960e-05,  ..., 1.2858e-02,\n",
       "            4.3031e-02, 2.8812e-02],\n",
       "           [1.3664e-02, 8.8521e-04, 1.2720e-03,  ..., 1.0773e-03,\n",
       "            6.9217e-03, 8.4036e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[8.6187e-02, 5.8544e-03, 2.5797e-03,  ..., 6.9914e-04,\n",
       "            6.8643e-03, 7.5210e-01],\n",
       "           [1.1118e-01, 5.5202e-02, 1.2644e-02,  ..., 4.4334e-05,\n",
       "            2.4608e-04, 8.0764e-01],\n",
       "           [5.3812e-02, 5.9038e-01, 1.6045e-02,  ..., 7.0685e-05,\n",
       "            8.2769e-04, 2.9558e-01],\n",
       "           ...,\n",
       "           [2.7695e-04, 1.3432e-04, 1.6010e-05,  ..., 7.8972e-03,\n",
       "            8.7702e-03, 1.8995e-02],\n",
       "           [5.6997e-03, 3.2960e-04, 1.1410e-04,  ..., 2.9818e-02,\n",
       "            6.5267e-02, 2.9035e-01],\n",
       "           [9.3074e-03, 3.5335e-04, 3.6992e-04,  ..., 4.4003e-04,\n",
       "            3.9221e-03, 7.5428e-01]],\n",
       " \n",
       "          [[3.0256e-03, 1.3764e-03, 2.0507e-03,  ..., 1.3378e-03,\n",
       "            8.4219e-04, 7.6980e-01],\n",
       "           [2.6392e-04, 5.0793e-03, 8.8000e-04,  ..., 2.6773e-05,\n",
       "            4.8336e-04, 9.8479e-01],\n",
       "           [2.1506e-04, 4.0492e-02, 2.2475e-03,  ..., 3.6825e-05,\n",
       "            1.3488e-04, 9.4410e-01],\n",
       "           ...,\n",
       "           [1.0890e-03, 2.4330e-04, 1.9637e-04,  ..., 1.2547e-03,\n",
       "            1.6562e-03, 9.6345e-01],\n",
       "           [3.7030e-03, 2.0525e-03, 9.2981e-04,  ..., 4.3609e-03,\n",
       "            1.3586e-03, 7.8428e-01],\n",
       "           [5.0651e-03, 3.3619e-04, 9.2043e-04,  ..., 1.6140e-03,\n",
       "            1.0380e-03, 8.3496e-01]],\n",
       " \n",
       "          [[5.1659e-03, 7.7826e-04, 1.3590e-03,  ..., 5.6472e-03,\n",
       "            1.0677e-01, 1.9066e-01],\n",
       "           [2.2505e-01, 3.5947e-03, 1.6564e-02,  ..., 2.5675e-05,\n",
       "            1.8341e-03, 7.2949e-01],\n",
       "           [1.0187e-02, 9.2011e-01, 2.5535e-02,  ..., 4.2263e-05,\n",
       "            2.9057e-04, 1.2808e-02],\n",
       "           ...,\n",
       "           [1.2901e-04, 8.8694e-05, 2.4530e-06,  ..., 8.8798e-03,\n",
       "            1.1379e-02, 7.0618e-04],\n",
       "           [7.7520e-06, 1.0566e-06, 1.1776e-03,  ..., 9.3380e-01,\n",
       "            4.8675e-03, 4.9642e-04],\n",
       "           [4.3390e-03, 4.8814e-04, 6.0949e-04,  ..., 9.8850e-04,\n",
       "            1.5660e-03, 8.0997e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.4311e-03, 2.2553e-04, 4.2527e-04,  ..., 4.4208e-03,\n",
       "            2.7552e-02, 4.5316e-01],\n",
       "           [1.2658e-02, 1.3508e-02, 1.1528e-03,  ..., 3.6327e-06,\n",
       "            1.8596e-04, 9.5033e-01],\n",
       "           [1.0466e-02, 2.4704e-02, 5.5501e-03,  ..., 1.8512e-04,\n",
       "            1.2445e-03, 9.0937e-01],\n",
       "           ...,\n",
       "           [4.8049e-04, 9.6037e-05, 3.2811e-04,  ..., 6.0815e-02,\n",
       "            3.9212e-02, 1.9771e-01],\n",
       "           [4.4568e-04, 7.4404e-05, 1.1796e-04,  ..., 2.4847e-02,\n",
       "            5.0548e-02, 6.1362e-01],\n",
       "           [7.8723e-03, 3.4660e-04, 2.0721e-04,  ..., 7.1036e-04,\n",
       "            4.8212e-03, 9.3516e-01]],\n",
       " \n",
       "          [[5.1751e-02, 1.9932e-02, 1.0684e-02,  ..., 6.6860e-04,\n",
       "            8.3594e-03, 3.2361e-01],\n",
       "           [2.5716e-03, 1.7465e-02, 1.4317e-02,  ..., 1.6791e-04,\n",
       "            1.9115e-03, 4.0960e-01],\n",
       "           [5.6030e-03, 5.0235e-03, 7.2487e-03,  ..., 5.3087e-04,\n",
       "            9.0032e-04, 8.0611e-01],\n",
       "           ...,\n",
       "           [3.6177e-03, 1.9892e-04, 7.8297e-04,  ..., 9.6933e-03,\n",
       "            3.6763e-02, 8.8771e-01],\n",
       "           [1.2303e-02, 1.9872e-04, 4.2486e-04,  ..., 6.0342e-03,\n",
       "            6.8294e-02, 8.1188e-01],\n",
       "           [7.7465e-03, 1.7661e-04, 1.6005e-04,  ..., 2.0077e-04,\n",
       "            8.7508e-04, 9.4162e-01]],\n",
       " \n",
       "          [[1.9239e-02, 5.0346e-02, 1.3111e-02,  ..., 1.3162e-03,\n",
       "            3.2105e-03, 5.1755e-01],\n",
       "           [5.3364e-03, 4.6624e-02, 2.2482e-01,  ..., 7.0209e-04,\n",
       "            2.5378e-04, 4.5056e-01],\n",
       "           [1.9065e-03, 2.2106e-02, 1.7178e-02,  ..., 3.4562e-04,\n",
       "            1.7160e-02, 2.5845e-01],\n",
       "           ...,\n",
       "           [3.5828e-03, 2.5204e-04, 4.4044e-04,  ..., 1.2353e-02,\n",
       "            7.9310e-01, 1.3146e-01],\n",
       "           [2.1657e-02, 1.4876e-02, 1.4342e-02,  ..., 2.0278e-02,\n",
       "            3.5847e-02, 7.8152e-01],\n",
       "           [1.6081e-02, 1.5478e-03, 1.2861e-03,  ..., 1.2157e-03,\n",
       "            2.4684e-03, 7.6856e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[9.4484e-03, 4.6670e-04, 3.9728e-04,  ..., 6.3455e-04,\n",
       "            4.6409e-03, 8.7730e-01],\n",
       "           [7.8781e-03, 4.8788e-03, 4.7210e-04,  ..., 3.7127e-05,\n",
       "            2.1745e-03, 9.7204e-01],\n",
       "           [9.2396e-03, 5.5506e-02, 1.4612e-02,  ..., 9.8815e-04,\n",
       "            1.8126e-03, 8.9769e-01],\n",
       "           ...,\n",
       "           [5.9067e-03, 1.8278e-03, 3.4353e-03,  ..., 3.6266e-02,\n",
       "            2.2586e-02, 5.4204e-01],\n",
       "           [4.4233e-03, 4.9219e-03, 5.7781e-04,  ..., 1.5079e-02,\n",
       "            1.1059e-01, 5.0216e-01],\n",
       "           [8.3106e-03, 7.0335e-04, 3.5806e-04,  ..., 6.4835e-04,\n",
       "            4.2783e-03, 8.4343e-01]],\n",
       " \n",
       "          [[2.1725e-02, 3.0316e-03, 2.6081e-03,  ..., 1.9579e-03,\n",
       "            9.3873e-03, 5.5027e-01],\n",
       "           [4.1896e-03, 5.3519e-03, 1.4923e-02,  ..., 3.6383e-04,\n",
       "            1.2961e-02, 4.6996e-01],\n",
       "           [5.9689e-03, 5.9370e-03, 1.0019e-02,  ..., 1.7223e-03,\n",
       "            5.0611e-03, 8.4855e-01],\n",
       "           ...,\n",
       "           [4.2817e-03, 1.9251e-04, 1.1381e-03,  ..., 6.3217e-02,\n",
       "            8.9308e-02, 8.0234e-01],\n",
       "           [1.0042e-02, 5.3535e-04, 2.0793e-03,  ..., 1.2530e-02,\n",
       "            2.4303e-02, 8.9553e-01],\n",
       "           [1.5745e-02, 1.5481e-04, 2.6728e-04,  ..., 5.9589e-04,\n",
       "            1.5236e-03, 9.2786e-01]],\n",
       " \n",
       "          [[3.4512e-04, 4.5533e-05, 2.7515e-05,  ..., 5.9545e-04,\n",
       "            9.8237e-01, 8.5092e-03],\n",
       "           [8.3252e-02, 1.6652e-02, 3.0203e-03,  ..., 1.1534e-04,\n",
       "            1.0199e-03, 8.2070e-01],\n",
       "           [5.0516e-03, 7.6302e-01, 7.8101e-03,  ..., 1.6604e-04,\n",
       "            6.7612e-05, 1.6780e-01],\n",
       "           ...,\n",
       "           [1.0216e-03, 4.6383e-02, 1.0491e-03,  ..., 4.6615e-03,\n",
       "            9.4570e-04, 7.7995e-02],\n",
       "           [6.6090e-04, 9.9938e-04, 8.7483e-04,  ..., 9.5165e-02,\n",
       "            1.8108e-01, 1.9286e-01],\n",
       "           [1.1334e-02, 4.8302e-04, 2.4904e-04,  ..., 1.5120e-03,\n",
       "            1.0081e-02, 8.7501e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.0742e-02, 2.7255e-03, 1.1287e-03,  ..., 2.3594e-03,\n",
       "            5.2304e-02, 3.3282e-01],\n",
       "           [8.2105e-04, 2.8062e-03, 4.4682e-03,  ..., 9.4874e-05,\n",
       "            6.8983e-03, 1.2291e-01],\n",
       "           [4.1852e-02, 4.9629e-03, 1.9547e-02,  ..., 5.0541e-04,\n",
       "            1.5097e-04, 8.4427e-01],\n",
       "           ...,\n",
       "           [1.0085e-01, 1.4936e-04, 7.9171e-04,  ..., 3.0711e-02,\n",
       "            2.3403e-02, 7.9390e-01],\n",
       "           [1.5241e-02, 3.8182e-05, 5.5118e-05,  ..., 1.5902e-03,\n",
       "            1.0036e-01, 8.3790e-01],\n",
       "           [2.5473e-02, 1.2362e-04, 1.4432e-04,  ..., 5.6315e-04,\n",
       "            2.3764e-03, 9.1653e-01]],\n",
       " \n",
       "          [[8.5825e-03, 9.0041e-03, 3.6419e-03,  ..., 1.8821e-02,\n",
       "            1.2868e-02, 8.4646e-02],\n",
       "           [9.0218e-03, 7.6436e-03, 2.1755e-03,  ..., 2.4658e-03,\n",
       "            4.9702e-03, 7.7243e-01],\n",
       "           [7.6754e-03, 1.6800e-02, 1.2354e-02,  ..., 3.3584e-03,\n",
       "            6.0611e-03, 6.8453e-01],\n",
       "           ...,\n",
       "           [7.9052e-02, 1.9001e-02, 1.5157e-02,  ..., 2.5064e-03,\n",
       "            9.0652e-03, 3.7026e-01],\n",
       "           [8.2335e-02, 8.8941e-03, 5.1065e-03,  ..., 1.7201e-03,\n",
       "            5.1755e-03, 3.0509e-01],\n",
       "           [1.0274e-02, 2.0397e-03, 1.6785e-03,  ..., 1.5980e-03,\n",
       "            1.8392e-02, 5.8985e-01]],\n",
       " \n",
       "          [[4.4910e-03, 5.4382e-02, 1.3859e-03,  ..., 1.9536e-03,\n",
       "            1.9302e-03, 5.2383e-01],\n",
       "           [3.5936e-05, 1.3749e-04, 1.2467e-01,  ..., 2.5830e-01,\n",
       "            4.8106e-04, 9.3273e-03],\n",
       "           [2.4791e-06, 2.0760e-07, 1.2996e-06,  ..., 7.3541e-06,\n",
       "            2.1877e-01, 5.1311e-04],\n",
       "           ...,\n",
       "           [2.6784e-06, 8.8121e-07, 5.9625e-06,  ..., 3.1844e-05,\n",
       "            4.3125e-01, 2.0828e-04],\n",
       "           [2.2273e-02, 2.0280e-02, 2.5938e-02,  ..., 1.1301e-02,\n",
       "            6.5068e-02, 2.7179e-01],\n",
       "           [1.1942e-02, 6.1228e-04, 6.4471e-04,  ..., 9.8282e-04,\n",
       "            1.5635e-03, 7.1473e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.1027e-02, 7.0241e-03, 4.0102e-03,  ..., 1.9371e-03,\n",
       "            7.9689e-03, 5.1015e-01],\n",
       "           [3.5076e-03, 1.4355e-02, 2.8050e-02,  ..., 3.9564e-04,\n",
       "            2.7707e-03, 6.7792e-01],\n",
       "           [2.2246e-03, 1.9104e-02, 2.7439e-02,  ..., 2.9766e-04,\n",
       "            1.1410e-03, 5.4293e-01],\n",
       "           ...,\n",
       "           [2.4751e-02, 8.9559e-05, 2.2247e-04,  ..., 4.4610e-02,\n",
       "            2.2369e-01, 5.8520e-01],\n",
       "           [6.4448e-03, 1.0190e-04, 2.8905e-04,  ..., 1.9763e-02,\n",
       "            6.4245e-02, 8.4256e-01],\n",
       "           [1.6043e-02, 6.3292e-04, 7.7333e-04,  ..., 1.2116e-03,\n",
       "            3.0193e-03, 8.2546e-01]],\n",
       " \n",
       "          [[3.0948e-03, 8.9006e-04, 3.6117e-04,  ..., 2.7198e-03,\n",
       "            3.1862e-03, 8.9622e-01],\n",
       "           [1.8622e-04, 6.8399e-04, 2.1440e-04,  ..., 8.8405e-06,\n",
       "            1.4368e-05, 9.8975e-01],\n",
       "           [1.2019e-03, 1.5788e-02, 2.7038e-03,  ..., 2.3692e-04,\n",
       "            2.9769e-04, 8.3555e-01],\n",
       "           ...,\n",
       "           [2.6283e-03, 1.5785e-03, 2.6753e-04,  ..., 5.9532e-02,\n",
       "            3.7632e-02, 3.5815e-01],\n",
       "           [1.6692e-03, 4.4481e-04, 4.8074e-05,  ..., 2.7344e-02,\n",
       "            2.9225e-02, 7.5120e-01],\n",
       "           [2.2700e-03, 1.1066e-04, 7.5642e-05,  ..., 2.1627e-04,\n",
       "            3.7736e-04, 9.6016e-01]],\n",
       " \n",
       "          [[1.4449e-02, 2.5380e-03, 6.0911e-04,  ..., 6.9331e-04,\n",
       "            7.4907e-03, 8.7630e-01],\n",
       "           [3.0308e-03, 1.7227e-02, 3.6051e-03,  ..., 4.1100e-05,\n",
       "            4.3849e-04, 9.3873e-01],\n",
       "           [6.6588e-03, 1.8891e-01, 2.5874e-02,  ..., 1.6731e-04,\n",
       "            1.6502e-03, 5.9120e-01],\n",
       "           ...,\n",
       "           [2.1520e-02, 3.6977e-04, 5.1522e-04,  ..., 3.4774e-02,\n",
       "            1.1514e-01, 5.3987e-01],\n",
       "           [1.4710e-02, 1.0905e-04, 1.1411e-04,  ..., 2.9406e-02,\n",
       "            8.2896e-02, 6.0495e-01],\n",
       "           [1.2802e-02, 1.4518e-03, 6.6020e-04,  ..., 1.8413e-03,\n",
       "            5.6247e-03, 8.4196e-01]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[1.3464e-02, 1.9236e-03, 2.2932e-04,  ..., 6.5531e-04,\n",
       "            1.5882e-02, 4.5672e-01],\n",
       "           [3.3883e-03, 1.9969e-01, 2.7080e-04,  ..., 2.2515e-04,\n",
       "            2.2172e-02, 1.5116e-01],\n",
       "           [6.0737e-04, 6.5019e-04, 1.5519e-01,  ..., 8.7987e-02,\n",
       "            1.6801e-03, 9.0191e-02],\n",
       "           ...,\n",
       "           [3.0522e-04, 2.3305e-04, 1.1385e-02,  ..., 1.0671e-01,\n",
       "            1.2352e-03, 1.4134e-02],\n",
       "           [5.0372e-03, 6.3535e-03, 1.0593e-04,  ..., 4.0533e-04,\n",
       "            1.7880e-01, 1.0301e-01],\n",
       "           [2.7787e-03, 1.2028e-03, 3.0717e-04,  ..., 3.4906e-04,\n",
       "            7.7453e-04, 7.5115e-01]],\n",
       " \n",
       "          [[6.0276e-03, 1.7755e-04, 5.6780e-04,  ..., 4.0825e-03,\n",
       "            7.2754e-03, 7.9446e-01],\n",
       "           [1.0016e-02, 4.9290e-03, 1.2019e-02,  ..., 1.8199e-04,\n",
       "            1.5253e-04, 9.2178e-01],\n",
       "           [1.1952e-02, 2.3580e-03, 9.1363e-03,  ..., 2.5639e-04,\n",
       "            1.2284e-04, 9.3692e-01],\n",
       "           ...,\n",
       "           [7.9427e-02, 1.0111e-03, 6.1266e-03,  ..., 3.3883e-02,\n",
       "            8.2219e-03, 7.7582e-01],\n",
       "           [1.0913e-01, 6.9662e-04, 2.5596e-03,  ..., 7.6165e-03,\n",
       "            2.0818e-03, 8.1287e-01],\n",
       "           [5.9678e-02, 1.1972e-03, 2.6121e-03,  ..., 3.5018e-03,\n",
       "            3.6478e-03, 4.9353e-01]],\n",
       " \n",
       "          [[9.8264e-03, 7.7001e-04, 1.2175e-03,  ..., 3.3160e-03,\n",
       "            1.5620e-02, 7.0140e-01],\n",
       "           [3.9932e-03, 1.1724e-03, 1.0007e-03,  ..., 5.4383e-05,\n",
       "            6.8249e-04, 8.9378e-01],\n",
       "           [1.9519e-03, 3.2823e-03, 6.8622e-04,  ..., 9.3483e-05,\n",
       "            5.8738e-04, 8.8002e-01],\n",
       "           ...,\n",
       "           [2.2877e-03, 8.0257e-05, 3.2316e-05,  ..., 3.3329e-03,\n",
       "            1.0009e-02, 9.3938e-01],\n",
       "           [2.5120e-03, 4.7880e-05, 4.8943e-05,  ..., 1.4171e-02,\n",
       "            1.1016e-02, 9.0228e-01],\n",
       "           [5.2628e-03, 4.3469e-03, 2.3496e-03,  ..., 6.1319e-03,\n",
       "            1.7668e-02, 2.4451e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[8.2727e-03, 4.2623e-05, 5.3705e-05,  ..., 2.9699e-04,\n",
       "            1.6957e-03, 8.6281e-01],\n",
       "           [6.6090e-03, 4.6345e-05, 1.3633e-05,  ..., 2.0804e-05,\n",
       "            3.1898e-03, 9.0325e-01],\n",
       "           [1.2698e-03, 1.4750e-01, 5.2726e-04,  ..., 4.2634e-04,\n",
       "            3.5666e-04, 2.8646e-01],\n",
       "           ...,\n",
       "           [5.5982e-04, 1.5176e-01, 1.1864e-03,  ..., 2.2589e-03,\n",
       "            1.6167e-03, 1.0909e-01],\n",
       "           [2.3513e-03, 7.0188e-03, 1.9330e-01,  ..., 7.8516e-02,\n",
       "            1.9021e-02, 5.0253e-01],\n",
       "           [1.9684e-02, 6.6976e-04, 4.1610e-04,  ..., 6.6459e-04,\n",
       "            3.0604e-03, 3.6933e-01]],\n",
       " \n",
       "          [[1.7596e-02, 1.4318e-03, 1.0936e-03,  ..., 1.7819e-03,\n",
       "            3.1506e-03, 4.0425e-01],\n",
       "           [1.0114e-03, 8.4347e-03, 8.5255e-03,  ..., 6.1307e-04,\n",
       "            5.4346e-03, 1.8348e-01],\n",
       "           [7.6780e-03, 3.3374e-03, 1.3514e-03,  ..., 1.2531e-04,\n",
       "            9.4564e-05, 8.3794e-01],\n",
       "           ...,\n",
       "           [3.6464e-02, 2.5650e-04, 1.6482e-04,  ..., 1.7905e-03,\n",
       "            1.2743e-03, 8.9353e-01],\n",
       "           [2.8673e-02, 7.9061e-05, 5.3754e-05,  ..., 5.6845e-04,\n",
       "            7.9930e-04, 9.2186e-01],\n",
       "           [1.2767e-02, 1.2491e-02, 2.8560e-03,  ..., 1.3769e-03,\n",
       "            1.7281e-03, 8.9480e-02]],\n",
       " \n",
       "          [[3.8615e-02, 2.5301e-03, 3.0538e-03,  ..., 1.4322e-02,\n",
       "            6.2754e-02, 2.1091e-01],\n",
       "           [1.8377e-02, 6.2479e-04, 9.7629e-04,  ..., 3.4665e-03,\n",
       "            6.5774e-03, 5.3676e-01],\n",
       "           [6.8874e-03, 5.4601e-03, 3.6088e-04,  ..., 1.0310e-03,\n",
       "            4.1546e-02, 4.6646e-01],\n",
       "           ...,\n",
       "           [2.8494e-02, 1.2154e-02, 1.0825e-03,  ..., 3.8495e-03,\n",
       "            5.3016e-02, 4.3704e-01],\n",
       "           [6.3906e-02, 2.0558e-03, 4.1919e-03,  ..., 7.6786e-03,\n",
       "            2.8321e-03, 5.9606e-01],\n",
       "           [1.9137e-02, 6.6994e-03, 4.7445e-03,  ..., 3.3708e-03,\n",
       "            9.7329e-03, 1.7316e-02]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[2.6138e-02, 7.9998e-03, 4.2400e-03,  ..., 1.1674e-02,\n",
       "            5.0939e-02, 5.2236e-02],\n",
       "           [2.5049e-02, 1.7452e-02, 5.7206e-03,  ..., 5.8615e-03,\n",
       "            1.3905e-02, 4.8794e-02],\n",
       "           [1.7919e-02, 2.1223e-02, 6.3541e-03,  ..., 7.5854e-03,\n",
       "            1.3816e-01, 5.1108e-02],\n",
       "           ...,\n",
       "           [1.6377e-02, 8.0826e-03, 3.4821e-03,  ..., 4.3632e-03,\n",
       "            3.2255e-02, 4.1781e-02],\n",
       "           [1.7318e-02, 2.8484e-02, 1.1965e-03,  ..., 9.0368e-04,\n",
       "            5.0795e-03, 2.3454e-02],\n",
       "           [4.1615e-02, 9.2113e-03, 3.4566e-03,  ..., 7.5893e-03,\n",
       "            3.1042e-02, 5.2151e-02]],\n",
       " \n",
       "          [[3.3514e-03, 8.8950e-05, 2.4551e-04,  ..., 5.0478e-04,\n",
       "            3.0464e-04, 6.5852e-03],\n",
       "           [1.4763e-04, 6.1091e-02, 8.6107e-05,  ..., 2.4679e-05,\n",
       "            4.1478e-04, 1.0328e-03],\n",
       "           [2.8503e-04, 9.1644e-04, 1.0405e-01,  ..., 2.0825e-02,\n",
       "            3.5623e-04, 3.5325e-03],\n",
       "           ...,\n",
       "           [5.5366e-04, 7.1034e-04, 9.5026e-02,  ..., 1.1930e-01,\n",
       "            3.0655e-03, 2.6610e-03],\n",
       "           [3.1539e-04, 1.6442e-03, 1.9566e-04,  ..., 4.2184e-04,\n",
       "            6.7144e-02, 1.1162e-03],\n",
       "           [8.9586e-04, 2.8621e-04, 8.8879e-05,  ..., 1.3967e-04,\n",
       "            5.7567e-04, 6.5626e-03]],\n",
       " \n",
       "          [[4.6601e-03, 1.6720e-03, 3.2448e-03,  ..., 5.8779e-03,\n",
       "            6.4933e-03, 5.4109e-02],\n",
       "           [9.4704e-04, 4.0758e-03, 4.7199e-03,  ..., 1.5168e-03,\n",
       "            1.0394e-03, 2.3883e-02],\n",
       "           [2.4479e-03, 7.9093e-03, 9.4706e-03,  ..., 1.9452e-03,\n",
       "            3.1560e-03, 4.6122e-02],\n",
       "           ...,\n",
       "           [1.1797e-02, 4.4631e-03, 5.9398e-03,  ..., 9.2649e-03,\n",
       "            5.3382e-02, 4.8928e-02],\n",
       "           [1.6898e-02, 1.4222e-03, 1.8661e-03,  ..., 3.9330e-03,\n",
       "            6.7776e-02, 2.4881e-02],\n",
       "           [2.4913e-02, 5.5854e-03, 6.6613e-03,  ..., 2.5468e-03,\n",
       "            2.4174e-03, 9.7401e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[3.8766e-03, 1.7530e-05, 2.6748e-05,  ..., 6.5840e-05,\n",
       "            8.2584e-04, 2.3728e-02],\n",
       "           [7.2141e-06, 3.6739e-01, 2.1882e-05,  ..., 6.5693e-06,\n",
       "            5.2098e-06, 3.0129e-04],\n",
       "           [5.2967e-05, 7.0078e-05, 2.2166e-01,  ..., 1.2022e-01,\n",
       "            8.5161e-05, 1.5949e-03],\n",
       "           ...,\n",
       "           [9.3613e-05, 1.7071e-05, 7.3244e-02,  ..., 1.5789e-01,\n",
       "            2.2631e-04, 1.3306e-03],\n",
       "           [2.4362e-04, 1.6501e-04, 1.1040e-04,  ..., 2.6296e-04,\n",
       "            5.8842e-02, 5.8501e-03],\n",
       "           [1.4444e-03, 6.0372e-04, 2.6702e-04,  ..., 2.1056e-04,\n",
       "            3.1734e-04, 1.1329e-02]],\n",
       " \n",
       "          [[6.6671e-04, 1.4819e-04, 1.2398e-03,  ..., 2.7326e-02,\n",
       "            1.2077e-01, 1.0380e-02],\n",
       "           [1.4563e-02, 5.5814e-03, 2.3731e-03,  ..., 1.9553e-02,\n",
       "            5.1296e-01, 5.2653e-02],\n",
       "           [8.7687e-02, 5.7851e-04, 4.2594e-02,  ..., 1.8186e-01,\n",
       "            2.7133e-02, 4.7079e-01],\n",
       "           ...,\n",
       "           [1.5444e-01, 1.4871e-04, 1.1989e-02,  ..., 8.4161e-02,\n",
       "            5.6359e-03, 6.8547e-01],\n",
       "           [4.3434e-01, 7.5890e-04, 3.8099e-04,  ..., 1.3139e-03,\n",
       "            4.5670e-02, 4.4130e-01],\n",
       "           [2.6840e-02, 3.2134e-03, 5.6496e-03,  ..., 1.7585e-02,\n",
       "            2.5396e-02, 3.4734e-02]],\n",
       " \n",
       "          [[5.0012e-02, 5.9633e-03, 3.3666e-03,  ..., 4.0057e-03,\n",
       "            1.8717e-03, 3.5850e-02],\n",
       "           [2.7862e-04, 4.2193e-04, 2.1291e-02,  ..., 1.6322e-02,\n",
       "            1.1351e-01, 1.6017e-02],\n",
       "           [3.5857e-04, 1.0153e-02, 2.2737e-02,  ..., 6.6083e-03,\n",
       "            7.2035e-03, 2.5191e-02],\n",
       "           ...,\n",
       "           [6.2687e-04, 9.7550e-04, 1.7267e-03,  ..., 1.2668e-02,\n",
       "            4.8229e-02, 1.2269e-02],\n",
       "           [2.9794e-04, 3.8740e-03, 2.4637e-03,  ..., 4.5521e-02,\n",
       "            4.1361e-02, 9.3569e-03],\n",
       "           [2.3066e-03, 7.7902e-03, 4.8058e-03,  ..., 5.8008e-03,\n",
       "            5.1047e-02, 2.5937e-02]]]], grad_fn=<SoftmaxBackward0>), tensor([[[[3.6051e-02, 1.4204e-02, 2.5285e-03,  ..., 2.0353e-03,\n",
       "            1.5292e-02, 2.1474e-02],\n",
       "           [1.7731e-03, 6.9524e-04, 1.0460e-03,  ..., 4.8333e-04,\n",
       "            2.4003e-03, 1.7369e-02],\n",
       "           [2.0810e-02, 1.6519e-03, 2.1448e-03,  ..., 1.5133e-03,\n",
       "            3.5260e-03, 3.8539e-02],\n",
       "           ...,\n",
       "           [3.2097e-02, 1.7678e-03, 3.7439e-03,  ..., 5.7216e-03,\n",
       "            9.2843e-03, 5.0466e-02],\n",
       "           [1.2814e-02, 6.8728e-03, 3.8114e-03,  ..., 5.7461e-03,\n",
       "            2.2244e-02, 3.9554e-02],\n",
       "           [4.2723e-03, 3.7312e-04, 1.6265e-04,  ..., 1.0178e-04,\n",
       "            7.0776e-04, 1.4421e-02]],\n",
       " \n",
       "          [[4.3481e-02, 3.9343e-04, 9.5850e-04,  ..., 7.0416e-03,\n",
       "            1.3853e-02, 3.2113e-02],\n",
       "           [1.8517e-03, 1.1212e-04, 1.8336e-04,  ..., 8.9794e-05,\n",
       "            2.2613e-03, 2.1770e-02],\n",
       "           [6.8773e-04, 1.3468e-03, 3.0296e-04,  ..., 8.1973e-05,\n",
       "            1.6887e-03, 1.5935e-02],\n",
       "           ...,\n",
       "           [8.9813e-03, 1.7297e-03, 3.7363e-04,  ..., 7.6861e-04,\n",
       "            3.1073e-02, 2.4023e-02],\n",
       "           [2.5134e-02, 1.5358e-02, 4.8884e-04,  ..., 1.7402e-03,\n",
       "            7.9686e-03, 5.0467e-02],\n",
       "           [4.0972e-03, 2.2290e-04, 2.9617e-04,  ..., 3.8178e-04,\n",
       "            2.0124e-03, 2.0031e-02]],\n",
       " \n",
       "          [[1.7073e-02, 1.3949e-03, 6.7226e-04,  ..., 5.3906e-03,\n",
       "            2.9721e-02, 2.9026e-02],\n",
       "           [7.2215e-03, 4.0555e-03, 2.2938e-03,  ..., 1.2882e-03,\n",
       "            3.1553e-03, 3.5347e-02],\n",
       "           [1.1470e-02, 3.7000e-03, 9.2031e-03,  ..., 3.2647e-03,\n",
       "            3.3831e-03, 3.3455e-02],\n",
       "           ...,\n",
       "           [2.0608e-02, 2.8562e-03, 5.6169e-03,  ..., 1.0274e-02,\n",
       "            1.3768e-02, 3.1002e-02],\n",
       "           [1.0521e-02, 2.6283e-03, 1.6228e-03,  ..., 3.8854e-03,\n",
       "            1.3182e-02, 3.3824e-02],\n",
       "           [5.0341e-03, 1.1596e-03, 2.0478e-03,  ..., 3.5112e-03,\n",
       "            4.2733e-03, 5.1674e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[3.3857e-02, 1.8710e-03, 2.4993e-03,  ..., 8.5306e-03,\n",
       "            6.4576e-02, 1.0492e-02],\n",
       "           [1.1238e-02, 3.8029e-02, 1.1827e-02,  ..., 4.6548e-03,\n",
       "            1.1298e-02, 2.6471e-02],\n",
       "           [1.1572e-02, 1.1178e-02, 1.2012e-01,  ..., 8.5530e-02,\n",
       "            1.1135e-02, 3.8729e-02],\n",
       "           ...,\n",
       "           [1.4128e-02, 9.6384e-03, 4.2028e-02,  ..., 1.2277e-01,\n",
       "            2.3627e-02, 4.3939e-02],\n",
       "           [6.3506e-03, 1.7417e-02, 7.6727e-03,  ..., 1.6344e-02,\n",
       "            1.3907e-01, 1.2840e-02],\n",
       "           [3.2404e-02, 2.8027e-03, 7.7927e-03,  ..., 8.4976e-03,\n",
       "            1.5495e-02, 5.2397e-02]],\n",
       " \n",
       "          [[4.7663e-03, 2.1554e-03, 7.0844e-04,  ..., 5.4992e-03,\n",
       "            8.5118e-02, 3.6992e-02],\n",
       "           [1.4633e-03, 9.2703e-03, 2.0294e-03,  ..., 8.4251e-04,\n",
       "            2.5368e-03, 2.2888e-02],\n",
       "           [2.5150e-03, 7.6727e-03, 2.4474e-02,  ..., 2.5363e-03,\n",
       "            2.1387e-03, 3.0057e-02],\n",
       "           ...,\n",
       "           [8.5499e-03, 1.8856e-03, 1.9420e-02,  ..., 1.3225e-02,\n",
       "            9.5743e-03, 4.0040e-02],\n",
       "           [1.7354e-02, 5.8426e-04, 2.1076e-03,  ..., 7.5319e-03,\n",
       "            9.4524e-03, 5.1795e-02],\n",
       "           [2.5090e-03, 2.6131e-04, 2.7911e-04,  ..., 3.3746e-04,\n",
       "            9.8720e-04, 2.4308e-02]],\n",
       " \n",
       "          [[1.7772e-03, 4.6375e-04, 6.1606e-04,  ..., 3.4615e-03,\n",
       "            2.1101e-02, 2.9442e-02],\n",
       "           [1.3730e-03, 3.5600e-03, 1.0561e-02,  ..., 1.8196e-03,\n",
       "            7.7948e-04, 5.1106e-03],\n",
       "           [2.4119e-03, 6.2593e-03, 1.6269e-02,  ..., 2.6926e-03,\n",
       "            1.2893e-03, 7.6691e-03],\n",
       "           ...,\n",
       "           [1.0157e-02, 4.1392e-03, 6.0615e-03,  ..., 1.0944e-02,\n",
       "            7.1390e-03, 1.3840e-02],\n",
       "           [1.2898e-02, 3.1034e-03, 3.6811e-03,  ..., 8.1793e-03,\n",
       "            1.2434e-02, 1.1794e-02],\n",
       "           [1.3491e-03, 5.8862e-04, 4.3188e-04,  ..., 8.5243e-04,\n",
       "            1.5642e-03, 8.8388e-03]]]], grad_fn=<SoftmaxBackward0>)), cross_attentions=None))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_only_pipeline.forward(ii_text, tti_text, am_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322f7447",
   "metadata": {},
   "source": [
    "# Binary Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c20ac33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0x7fa450563c40>\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "36",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 36",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1031/3734994465.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmarmot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_trainer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbinary_trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbinary_trainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarmot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatching_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/teams/jack_areen_rubin/MARMOT/marmot/scripts/binary_trainer.py\u001b[0m in \u001b[0;36mbinary_trainer\u001b[0;34m(model, train_dataset, validation_dataset, epochs, learning_rate, batch_size, epoch_freeze_img, epoch_freeze_txt, gradient_clipping, gc_value, proportion_warmup_steps, weight, device)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4089\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4090\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4091\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4092\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m             ):\n\u001b[1;32m   3808\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3809\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3810\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3811\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 36"
     ]
    }
   ],
   "source": [
    "from marmot.scripts.binary_trainer import binary_trainer\n",
    "\n",
    "binary_trainer = binary_trainer(marmot, matching_rows, matching_rows, epochs=1, learning_rate=1e-5, batch_size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8243d3",
   "metadata": {},
   "source": [
    "# Binary classifer.\n",
    "\n",
    "Do I need to run forward() methods before the binary classifier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f88595",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
